{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-1bcf45fe78d7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[0mopt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_train_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-7-1bcf45fe78d7>\u001B[0m in \u001B[0;36mget_train_args\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_train_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mparser\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margparse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mArgumentParser\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_argument\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'--batch_size'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdefault\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mhelp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'每批数据的数量'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_argument\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'--nepoch'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdefault\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mhelp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'训练的轮次'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_argument\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'--lr'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdefault\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.001\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mhelp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'学习率'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "def get_train_args():\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch_size',type=int,default=10,help = '每批数据的数量')\n",
    "    parser.add_argument('--nepoch',type=int,default=3,help = '训练的轮次')\n",
    "    parser.add_argument('--lr',type=float,default=0.001,help = '学习率')\n",
    "    parser.add_argument('--gpu',type=bool,default=True,help = '是否使用gpu')\n",
    "    parser.add_argument('--num_workers',type=int,default=2,help='dataloader使用的线程数量')\n",
    "    parser.add_argument('--num_labels',type=int,default=3,help='分类类数')\n",
    "    parser.add_argument('--data_path',type=str,default='./data',help='数据路径')\n",
    "    opt=parser.parse_args()\n",
    "    print(opt)\n",
    "    return opt\n",
    "\n",
    "opt = get_train_args()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar\n",
      "bar\n",
      "foo bar\n",
      "foo1 bar1\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class DotDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        dict.__init__(self, *args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "d = DotDict()\n",
    "d.foo = 'bar'\n",
    "d.foo1 = 'bar1'\n",
    "print(d['foo'])\n",
    "print(d.foo)\n",
    "\n",
    "for k,v in d.items():\n",
    "    print(k,v)\n",
    "\n",
    "opt1 = DotDict({'num_labels' : 3})\n",
    "print(opt1.num_labels)\n",
    "\n",
    "opt2 = DotDict(num_labels = 3,)\n",
    "print(opt2.num_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "opt3 = DotDict(\n",
    "    num_labels = 3,\n",
    "    batch_size = 10,\n",
    "    num_workers = 8,\n",
    "    cache_dir = '../../PretrainedData/Transformers/bert-base-chinese',\n",
    "    data_path = 'data',\n",
    "    nepoch = 3,\n",
    "               )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at ../../PretrainedData/Transformers/bert-base-chinese\\8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at ../../PretrainedData/Transformers/bert-base-chinese\\b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at ../../PretrainedData/Transformers/bert-base-chinese\\8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.tokenization_bert.BertTokenizer object at 0x0000013DCDECA048>\n"
     ]
    }
   ],
   "source": [
    "# num_labels是分类的类数\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese',\n",
    "                                                         num_labels=opt3.num_labels,\n",
    "                                                         cache_dir = opt3.cache_dir,\n",
    "                                                         )\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese',\n",
    "                                          cache_dir = opt3.cache_dir,)\n",
    "print(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 69782363f8264714b60ba699aff87e61,2\n",
      "\n",
      "1000 d6b520b3a93643c7855cc9ca4262bd0f,1\n",
      "\n",
      "1500 4c4990a462b24b2787ddb75d69d68beb,1\n",
      "\n",
      "2000 c67b1254e8a746a78df818c54001ee8d,1\n",
      "\n",
      "2500 45e0fe90c3e845c397e8e7c8a021019d,2\n",
      "\n",
      "3000 80aea805d1064025864224914ae28949,1\n",
      "\n",
      "3500 77486e8fafa94f42985c20a46c0b5b0a,2\n",
      "\n",
      "4000 21e36b376b2e4b4988736494c995e57f,1\n",
      "\n",
      "4500 728cbcbcecf84cfe87ded2b2f2801616,2\n",
      "\n",
      "5000 8ad5c7afb24948b0b3d1aae7ec6311c0,1\n",
      "\n",
      "5500 4e3c9fa942d9425b90397f4a0b008180,1\n",
      "\n",
      "6000 c7d498d2bac14644b7f8cfb67a3fb3ed,2\n",
      "\n",
      "6500 35f7358beb72448095ffe1579128d1d4,2\n",
      "\n",
      "7000 86486e5c075c4534ab7a0e2c3240108c,2\n",
      "\n",
      "500 69782363f8264714b60ba699aff87e61,2\n",
      "\n",
      "1000 d6b520b3a93643c7855cc9ca4262bd0f,1\n",
      "\n",
      "1500 4c4990a462b24b2787ddb75d69d68beb,1\n",
      "\n",
      "2000 c67b1254e8a746a78df818c54001ee8d,1\n",
      "\n",
      "2500 45e0fe90c3e845c397e8e7c8a021019d,2\n",
      "\n",
      "3000 80aea805d1064025864224914ae28949,1\n",
      "\n",
      "3500 77486e8fafa94f42985c20a46c0b5b0a,2\n",
      "\n",
      "4000 21e36b376b2e4b4988736494c995e57f,1\n",
      "\n",
      "4500 728cbcbcecf84cfe87ded2b2f2801616,2\n",
      "\n",
      "5000 8ad5c7afb24948b0b3d1aae7ec6311c0,1\n",
      "\n",
      "5500 4e3c9fa942d9425b90397f4a0b008180,1\n",
      "\n",
      "6000 c7d498d2bac14644b7f8cfb67a3fb3ed,2\n",
      "\n",
      "6500 35f7358beb72448095ffe1579128d1d4,2\n",
      "\n",
      "7000 86486e5c075c4534ab7a0e2c3240108c,2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NewsData(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, is_train=1):\n",
    "        self.data_num = 7346\n",
    "        self.x_list = []\n",
    "        self.y_list = []\n",
    "        self.posi = []\n",
    "\n",
    "        with open(root + '/Train_DataSet.csv', encoding='UTF-8') as f:\n",
    "            for i in range(self.data_num + 1):\n",
    "                line = f.readline()[:-1] + '这是一个中性的数据'\n",
    "\n",
    "                data_one_str = line.split(',')[len(line.split(',')) - 2]\n",
    "                data_two_str = line.split(',')[len(line.split(',')) - 1]\n",
    "\n",
    "                if len(data_one_str) < 6:\n",
    "                    z = len(data_one_str)\n",
    "                    data_one_str = data_one_str + '，' + data_two_str[0:min(200, len(data_two_str))]\n",
    "                else:\n",
    "                    data_one_str = data_one_str\n",
    "                if i == 0:\n",
    "                    continue\n",
    "\n",
    "                word_l = tokenizer.encode(data_one_str, add_special_tokens=False)\n",
    "                if len(word_l) < 100:\n",
    "                    while (len(word_l) != 100):\n",
    "                        word_l.append(0)\n",
    "                else:\n",
    "                    word_l = word_l[0:100]\n",
    "\n",
    "                word_l.append(102)\n",
    "                l = word_l\n",
    "                word_l = [101]\n",
    "                word_l.extend(l)\n",
    "\n",
    "                self.x_list.append(torch.tensor(word_l))\n",
    "\n",
    "                self.posi.append(torch.tensor([i for i in range(102)]))\n",
    "\n",
    "        with open(root + '/Train_DataSet_Label.csv', encoding='UTF-8') as f:\n",
    "            for i in range(self.data_num + 1):\n",
    "                tempStr = f.readline()\n",
    "                if i % 500 == 499:\n",
    "                    print(i + 1, tempStr)\n",
    "                label_one = tempStr[-2]\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                label_one = int(label_one)\n",
    "                self.y_list.append(torch.tensor(label_one))\n",
    "\n",
    "        # 训练集或者是测试集\n",
    "        if is_train == 1:\n",
    "            self.x_list = self.x_list[0:6000]\n",
    "            self.y_list = self.y_list[0:6000]\n",
    "            self.posi = self.posi[0:6000]\n",
    "        else:\n",
    "            self.x_list = self.x_list[6000:]\n",
    "            self.y_list = self.y_list[6000:]\n",
    "            self.posi = self.posi[6000:]\n",
    "\n",
    "        self.len = len(self.x_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_list[index], self.y_list[index], self.posi[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "def get_data(opt):\n",
    "    #NewsData继承于pytorch的Dataset类\n",
    "    trainset = NewsData(opt.data_path,is_train = 1)\n",
    "    trainloader=torch.utils.data.DataLoader(trainset,\n",
    "                                            batch_size=opt.batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=opt.num_workers)\n",
    "    testset = NewsData(opt.data_path,is_train = 0)\n",
    "    testloader=torch.utils.data.DataLoader(testset,\n",
    "                                           batch_size=opt.batch_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=opt.num_workers)\n",
    "    return trainloader, testloader\n",
    "trainloader, testloader = get_data(opt3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda.is_available True\n"
     ]
    }
   ],
   "source": [
    "print('cuda.is_available',torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train(epoch, model, trainloader, testloader, optimizer, opt):\n",
    "    print('\\ntrain-Epoch: %d' % (epoch + 1))\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    print_step = int(len(trainloader) / 10)\n",
    "    for batch_idx, (sue, label, posi) in enumerate(trainloader):\n",
    "        if opt.gpu:\n",
    "            sue = sue.cuda()\n",
    "            posi = posi.cuda()\n",
    "            label = label.unsqueeze(1).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # 输入参数为词列表、位置列表、标签\n",
    "        outputs = model(sue, position_ids=posi, labels=label)\n",
    "\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % print_step == 0:\n",
    "            print(\"Epoch:%d [%d|%d] loss:%f\" % (epoch + 1, batch_idx, len(trainloader), loss.mean()))\n",
    "    print(\"time:%.3f\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-Epoch: 1\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-ec85b68673c4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'./model.pth'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopt3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m         \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtestloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopt3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m         \u001B[0mtestFunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtestloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopt3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'./model.pth'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-964d530f9fb0>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(epoch, model, trainloader, testloader, optimizer, opt)\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mstart_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mprint_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainloader\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0msue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mposi\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgpu\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m             \u001B[0msue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    277\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0m_SingleProcessDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    278\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 279\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_MultiProcessingDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    280\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m    717\u001B[0m             \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    718\u001B[0m             \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 719\u001B[1;33m             \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    720\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    721\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\anaconda3\\envs\\pytorch\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\anaconda3\\envs\\pytorch\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    221\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\anaconda3\\envs\\pytorch\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\anaconda3\\envs\\pytorch\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     87\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\anaconda3\\envs\\pytorch\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "def testFunc(epoch, model, trainloader, testloader, opt):\n",
    "    print('\\ntest-Epoch: %d' % (epoch + 1))\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sue, label, posi) in enumerate(testloader):\n",
    "            if opt.gpu:\n",
    "                sue = sue.cuda()\n",
    "                posi = posi.cuda()\n",
    "                labels = label.unsqueeze(1).cuda()\n",
    "                label = label.cuda()\n",
    "            else:\n",
    "                labels = label.unsqueeze(1)\n",
    "\n",
    "            outputs = model(sue, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "\n",
    "            total += sue.size(0)\n",
    "            correct += predicted.data.eq(label.data).cpu().sum()\n",
    "\n",
    "    s = (\"Acc:%.3f\" % ((1.0 * correct.numpy()) / total))\n",
    "    print(s)\n",
    "\n",
    "if not os.path.exists('./model.pth'):\n",
    "    for epoch in range(opt3.nepoch):\n",
    "        train(epoch, model, trainloader, testloader, optimizer, opt3)\n",
    "        testFunc(epoch, model, trainloader, testloader, opt3)\n",
    "    torch.save(model.state_dict(), './model.pth')\n",
    "else:\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "    print('模型存在,直接test')\n",
    "    testFunc(0, model, trainloader, testloader, opt3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}