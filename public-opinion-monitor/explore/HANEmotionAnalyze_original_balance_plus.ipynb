{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"name":"HANEmotionAnalyze_original_balance_plus.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"k-CIbt4LqMiS","colab_type":"text"},"source":["## 开始"]},{"cell_type":"code","metadata":{"id":"zBDjArJoT65A","colab_type":"code","outputId":"94d02e30-b95a-472a-bf4e-67b68d2a5217","executionInfo":{"status":"ok","timestamp":1588346784416,"user_tz":-480,"elapsed":84530,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/Colab Notebooks/OursRepository/public-opinion-monitor\n","\n","!pip install thulac\n","!pip install jieba"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/Colab Notebooks/OursRepository/public-opinion-monitor\n","Collecting thulac\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/f2/f5893d06e744fe228f06ea1f340c90d15f55b0e3b0148762ab234af4573c/thulac-0.2.1.tar.gz (52.9MB)\n","\u001b[K     |████████████████████████████████| 52.9MB 58kB/s \n","\u001b[?25hBuilding wheels for collected packages: thulac\n","  Building wheel for thulac (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for thulac: filename=thulac-0.2.1-cp36-none-any.whl size=53141671 sha256=12589de93b86be7c0dddf8f6c1b8e0e57b87dd9d424622f19cb4947226cb1ed8\n","  Stored in directory: /root/.cache/pip/wheels/db/36/4a/1ac1e9b9ce727a9dfc7fa20092992707d7da162df871c8488f\n","Successfully built thulac\n","Installing collected packages: thulac\n","Successfully installed thulac-0.2.1\n","Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (0.42.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"9Eush51XTobh","colab_type":"code","outputId":"81970558-36a7-4f70-93ce-641ae192c7ac","executionInfo":{"status":"ok","timestamp":1588346795271,"user_tz":-480,"elapsed":95376,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# from ClassicalHANModel import *\n","from HANModel import *\n","import torch\n","import torch.nn as nn\n","from torch.optim.optimizer import Optimizer\n","import numpy\n","import time, math\n","import torch.utils.data as data\n","import os\n","import pandas as pd\n","import json\n","\n","import jieba\n","import thulac\n","thulacObj = thulac.thulac(seg_only=True)\n","class thulac_cutor:\n","    def cut(self,sentence:str):\n","        return thulacObj.fast_cut(sentence, text=True)\n","thulac_cutor = thulac_cutor()\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Model loaded succeed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"DUFj-U3PTobn","colab_type":"code","outputId":"0a6773db-759f-468e-a1fb-6ed63a3755c3","executionInfo":{"status":"ok","timestamp":1588346795272,"user_tz":-480,"elapsed":95370,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":449}},"source":["# import torch.functional as F\n","# \n","embedding = nn.Embedding(10, 3)\n","input = torch.LongTensor([[0, 1,2,4,5],[1, 4,3,2,9]])\n","print(embedding(input))\n","embedding2 = nn.Embedding(10, 3, padding_idx=2)\n","# input = torch.LongTensor([[1,2,0,5, 6,7,8,9]])\n","print(embedding2(input))\n","weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n","embedding3 = nn.Embedding.from_pretrained(weight)\n","input = torch.LongTensor([1])\n","print(embedding3(input))\n","input = torch.LongTensor([0])\n","print(embedding3(input))\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([[[ 0.0276,  0.8608, -1.5780],\n","         [-0.4675,  0.7026,  2.8824],\n","         [-0.9762,  0.4650,  0.9589],\n","         [ 0.2875,  0.6856,  0.1662],\n","         [ 0.8828, -0.2930, -0.1693]],\n","\n","        [[-0.4675,  0.7026,  2.8824],\n","         [ 0.2875,  0.6856,  0.1662],\n","         [-0.1699,  0.6954,  0.3241],\n","         [-0.9762,  0.4650,  0.9589],\n","         [ 1.2198, -0.6955, -1.3315]]], grad_fn=<EmbeddingBackward>)\n","tensor([[[ 0.9459, -0.2990,  0.1379],\n","         [-0.4660, -0.5365, -0.3199],\n","         [ 0.0000,  0.0000,  0.0000],\n","         [ 0.7131, -1.6717, -0.6272],\n","         [-0.1469,  2.1055,  0.4109]],\n","\n","        [[-0.4660, -0.5365, -0.3199],\n","         [ 0.7131, -1.6717, -0.6272],\n","         [ 1.3813,  2.5992,  2.2755],\n","         [ 0.0000,  0.0000,  0.0000],\n","         [-0.8800,  0.2352, -0.2075]]], grad_fn=<EmbeddingBackward>)\n","tensor([[4.0000, 5.1000, 6.3000]])\n","tensor([[1.0000, 2.3000, 3.0000]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"3HmMThKsTobr","colab_type":"text"},"source":["## 读取词向量\n","建立词语列表"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"hhmz_drpTobs","colab_type":"code","outputId":"1370ef7b-bdf8-4243-e052-f7f9b5c2b59c","executionInfo":{"status":"ok","timestamp":1588346813701,"user_tz":-480,"elapsed":113793,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["from gensim.models import KeyedVectors, Word2Vec\n","\n","# file = '../../PretrainedData/Tencent_AILab_ChineseEmbedding/Tencent_AILab_ChineseEmbedding.txt'\n","# file = '../../DataSets/Word2Vect/xingrong_50_thulac/word2vect_50_w5.model'\n","# file = '../../DataSets/Word2Vect/xiejunjie_300_jieba/wiki_han_word2vec_300维度.model'\n","file = '../../DataSets/Word2Vect/Tencent_AILab_ChineseEmbedding/Tencent_AILab_ChineseEmbedding_Min.txt'\n","# word2vec = Word2Vec.load(file)\n","word2vec = KeyedVectors.load_word2vec_format(file, binary=False,limit=100000)\n","# word2vec = KeyedVectors.load_word2vec_format(file, binary=False)\n","word2vec.init_sims(replace=True)  # 神奇，很省内存，可以运算most_similar\n","word2vec.vector_size"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"_zCpfSvDTocC","colab_type":"code","outputId":"393a5471-d342-4019-f023-4023231273c6","executionInfo":{"status":"ok","timestamp":1588346813702,"user_tz":-480,"elapsed":113787,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":577}},"source":["print(word2vec)\n","# print(word2vec.wv.vocab)\n","# print(len(word2vec.index2word))\n","print(len(word2vec.wv.index2word))\n","print(word2vec.wv.index2word[0])\n","print(word2vec.wv.index2word[1])\n","print(word2vec.wv.index2word[2])\n","print(word2vec.wv.index2word[1522])\n","print(word2vec.wv.index2entity[1522])\n","print(word2vec.similar_by_word('中国'))\n","print(word2vec.similar_by_word('天才'))\n","print(word2vec.wv)\n","print('word2vec.wv.vocab ---- >', word2vec.wv.vocab)\n","print(word2vec.wv.index2word)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"lzs2-uceTocG","colab_type":"code","outputId":"12bef0d4-477a-436f-ac49-094e5eb16832","executionInfo":{"status":"ok","timestamp":1588346813702,"user_tz":-480,"elapsed":113780,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":161}},"source":["wordEmbedding = [word2vec.wv[word]  for word in word2vec.wv.index2word]\n","word2index = { word:i for i, word in enumerate(word2vec.wv.index2word)}\n","# print(wordEmbedding[:2])\n","# print(word2index['中国'])\n","# print(word2index['天才'])\n","print(word2index['喜欢'])\n","print(word2index['不'])\n","print(word2index['爽'])\n","print(word2index['超赞'])\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"stream","text":["217\n","64\n","5313\n","41047\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"cy9vhIUoTocL","colab_type":"text"},"source":["## 读取训练数据"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"gZGmiumwTocN","colab_type":"code","outputId":"92692857-13e5-40e2-b958-af35608116ec","executionInfo":{"status":"ok","timestamp":1588346813703,"user_tz":-480,"elapsed":113775,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["def compute_ngrams(word, num_min = 1, num_max = 3):\n","    ngrams =[]\n","    for ngram_length in range(num_min, min(len(word), num_max) + 1):\n","        for i in range(len(word) - ngram_length + 1):\n","            # print(i, i + ngram_length)\n","            ngrams.append(word[i : i + ngram_length])\n","    # print(ngrams)\n","    return list(set(ngrams))\n","\n","print(compute_ngrams('you'))\n","print(compute_ngrams('I Think'))\n","print(compute_ngrams('中华人民共和国万岁'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['you', 'y', 'ou', 'o', 'u', 'yo']\n","['n', 'k', 'hin', ' ', 'I', 'Thi', ' T', 'h', 'hi', 'nk', 'I T', 'ink', 'Th', 'T', 'i', 'in', 'I ', ' Th']\n","['共和', '中华人', '国万', '人', '国万岁', '万', '和', '共和国', '国', '人民', '岁', '民共', '华人民', '中华', '民共和', '共', '人民共', '华', '和国', '华人', '万岁', '和国万', '民', '中']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"ulsoTSc2TocT","colab_type":"code","colab":{}},"source":["# 从词向量文本文件 word2vec 中获取词向量，如果获取到直接返回，若没有获取到，那么把这个词拆开\n","# 成为 ngrams 的新词组，并在 word2vec 中找新词组中的词向量并相加取平均，最后得到平均词向量输出\n","def wordVec(word, word2vec, min_n = 1, max_n = 3):\n","    # 确认词向量维度\n","    word_size = word2vec.wv.syn0[0].shape[0]\n","\n","    # 如果在词典之中，直接返回词向量\n","    if word in word2vec.wv.vocab.keys():\n","        return word2vec[word]\n","    else:\n","        # 计算word的ngrams词组\n","        ngrams = compute_ngrams(word, min_n, max_n)\n","        # 不在词典的情况下\n","        word_vec = numpy.zeros(word_size, dtype=numpy.float32)\n","        ngrams_found = 0\n","        ngrams_single = [ng for ng in ngrams if len(ng) == 1]\n","        ngrams_more = [ng for ng in ngrams if len(ng) > 1]\n","        # 先只接受2个单词长度以上的词向量\n","        for ngram in ngrams_more:\n","            if ngram in word2vec.wv.vocab.keys():\n","                word_vec += word2vec[ngram]\n","                ngrams_found += 1\n","                #print(ngram)\n","        # 如果，没有匹配到，那么最后是考虑单个词向量\n","        if ngrams_found == 0:\n","            for ngram in ngrams_single:\n","                word_vec += word2vec[ngram]\n","                ngrams_found += 1\n","        if word_vec.any():\n","            return word_vec / max(1, ngrams_found)\n","        else:\n","            # 不抛出异常，而是打印提示，并返回0向量。\n","            print(KeyError('all ngrams for word %s absent from model' % word))\n","            return word_vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"08tJP4HHTocX","colab_type":"code","colab":{}},"source":["class DotDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        dict.__init__(self, *args, **kwargs)\n","        self.__dict__ = self\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"XGUX_N8KToca","colab_type":"code","outputId":"c3cb0174-45e1-4904-b413-ec02aa6c212e","executionInfo":{"status":"ok","timestamp":1588346813705,"user_tz":-480,"elapsed":113764,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["import pandas as pd\n","\n","dic = {'a':[1, 2, 3, 4], 'b':[5, 6, 7, 8],\n","'c':[9, 10, 11, 12], 'd':[13, 14, 15, 16]}\n","df1=pd.DataFrame(dic)\n","print(df1)\n","df2=df1.sample(frac=0.75)\n","print(df2)\n","# rowlist=[]\n","# for indexs in df2.index:\n","#     rowlist.append(indexs)\n","df3=df1.drop(df2.index.to_list(),axis=0)\n","print(df3)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["   a  b   c   d\n","0  1  5   9  13\n","1  2  6  10  14\n","2  3  7  11  15\n","3  4  8  12  16\n","   a  b   c   d\n","3  4  8  12  16\n","1  2  6  10  14\n","0  1  5   9  13\n","   a  b   c   d\n","2  3  7  11  15\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lfY5Is_4I34d","colab_type":"code","outputId":"46961b4b-a124-45de-ba99-5fc2c41b7ceb","executionInfo":{"status":"ok","timestamp":1588346813706,"user_tz":-480,"elapsed":113759,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["import re\n","\n","def splitText(text:str, splitChar = '(。|，|,|！|\\!|？|\\?|\\n|\\t)'):\n","  '''\n","  句子切分分隔符\n","  '''\n","  contents = re.split(splitChar, text)\n","  contents = [\"\".join([a, b]) if b != '\\n' and b != '\\t' else \"\" #a + \"。\"\n","              for a, b in zip(contents[0::2], contents[1::2])]\n","  contents = [content for content in contents if content.strip() != '' and content[0] != '。']\n","  # for i, sen in enumerate(contents):\n","  #     print(i, sen)\n","  return contents\n","\n","testStr = \"\"\"\n","深圳，简称“深”，别称鹏城，是广东省副省级市、计划单列市、超大城市，国务院批复确定的中国经济特区、全国性经济中心城市和国际化城市 [1]  。截至2018年末，全市下辖9个区，总面积1997.47平方千米，建成区面积927.96平方千米，常住人口1302.66万人，城镇人口1302.66万人，城镇化率100%，是中国第一个全部城镇化的城市。 [2-5] \n","深圳地处中国华南地区、广东南部、珠江口东岸，东临大亚湾和大鹏湾，西濒珠江口和伶仃洋，南隔深圳河与香港相连，是粤港澳大湾区四大中心城市之一 [6]  、国家物流枢纽、国际性综合交通枢纽 [7]  、国际科技产业创新中心 [8]  、中国三大全国性金融中心之一 [9-10]  ，并全力建设中国特色社会主义先行示范区 [11]  、综合性国家科学中心 [12]  、全球海洋中心城市 [13]  。深圳水陆空铁口岸俱全，是中国拥有口岸数量最多、出入境人员最多、车流量最大的口岸城市。 [14]\n","\"\"\"\n","\n","print(splitText(testStr))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['深圳，', '简称“深”，', '别称鹏城，', '是广东省副省级市、计划单列市、超大城市，', '国务院批复确定的中国经济特区、全国性经济中心城市和国际化城市 [1]  。', '截至2018年末，', '全市下辖9个区，', '总面积1997.47平方千米，', '建成区面积927.96平方千米，', '常住人口1302.66万人，', '城镇人口1302.66万人，', '城镇化率100%，', '是中国第一个全部城镇化的城市。', '深圳地处中国华南地区、广东南部、珠江口东岸，', '东临大亚湾和大鹏湾，', '西濒珠江口和伶仃洋，', '南隔深圳河与香港相连，', '是粤港澳大湾区四大中心城市之一 [6]  、国家物流枢纽、国际性综合交通枢纽 [7]  、国际科技产业创新中心 [8]  、中国三大全国性金融中心之一 [9-10]  ，', '并全力建设中国特色社会主义先行示范区 [11]  、综合性国家科学中心 [12]  、全球海洋中心城市 [13]  。', '深圳水陆空铁口岸俱全，', '是中国拥有口岸数量最多、出入境人员最多、车流量最大的口岸城市。']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"1oqKk8CETocd","colab_type":"code","outputId":"ad73d65c-c96c-4e95-d1c0-e57ea4bd64d9","executionInfo":{"status":"ok","timestamp":1588346924537,"user_tz":-480,"elapsed":224583,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["def isNan(a):\n","    return a != a\n","\n","\n","class RatingData(data.Dataset):\n","    def __init__(self, path, \n","          word2index, \n","          max_row = -1, \n","          num_word_in_sentence = 10,\n","          num_sentence_in_article = 10,\n","          trainTestRate = 0.85, \n","          isTrain = True, \n","          wordCuter = thulac,\n","          clean_file_name = 'ratings_clean_4_HAN.csv',\n","          ):\n","        self.token_list = []\n","        self.label_list = []\n","        # self.token_positions = torch.tensor([i for i in range(100)])\n","\n","        print(' balance_data.csv 所在path:',path) # 地址不应该包含 ratings.csv\n","\n","        ratings_clean_filename = os.path.join(path, clean_file_name)\n","        ratings_filename = os.path.join(path, 'balance_data.csv')\n","        if os.path.isfile(ratings_clean_filename):\n","            clean_pd = pd.read_csv(ratings_clean_filename)\n","        else:\n","            print('没有找到缓存的文件%s, 读取源文件%s'%(ratings_clean_filename, ratings_filename))\n","            ratings_pd = pd.read_csv(ratings_filename)\n","            print('开始生成缓存文件%s'%(ratings_clean_filename))\n","            clean_pd = pd.DataFrame({\n","                'labels':[],\n","                'data':[],\n","            })\n","            nonRatingCount = 0\n","            for i, row in ratings_pd.iterrows():\n","                if max_row != -1 and i > max_row:\n","                    break\n","                if not isinstance(row['data'], str) or row['data'] == '':\n","                    # print(i + 1, row['comment'])\n","                    nonRatingCount += 1\n","                    continue\n","                r0 = row['labels']\n","                if r0 == -1:\n","                    r0 = 2\n","                    \n","                if i % 10000 == 9999:\n","                    print(i + 1, r0)\n","\n","                # 把文章切割成句子\n","                sentences = splitText(row['data'])\n","                tokens = []\n","                for i in range(num_sentence_in_article):\n","                  if i < len(sentences):\n","                    # 把句子切割成词\n","                    words = list(wordCuter.cut(sentences[i]))\n","                    # 把词转成词向量中的index，不足时补全\n","                    token = [ word2index[words[j]] if j < len(words) and words[j] in word2index else 0 \n","                          for j in range(num_word_in_sentence)] \n","                    tokens += token\n","                  else:\n","                    # 不足时补全\n","                    tokens += [0] * num_word_in_sentence\n","                \n","                newRow = DotDict()\n","\n","                newRow.labels = [r0]\n","                newRow.data = [json.dumps(tokens)]\n","\n","                clean_pd = clean_pd.append(pd.DataFrame(newRow), ignore_index=True)\n","            print('空的评论数量： %d'%(nonRatingCount))\n","            clean_pd.to_csv(ratings_clean_filename)\n","\n","        # 读取\n","        if isTrain:\n","            temp_pd = clean_pd.sample(frac=trainTestRate)\n","        else:\n","            temp_pd = clean_pd.sample(frac=trainTestRate)\n","            temp_pd = clean_pd.drop(temp_pd.index.tolist(), axis=0)\n","\n","        for i, row in temp_pd.iterrows():\n","            if max_row != -1 and i > max_row:\n","                break\n","\n","            self.label_list.append(torch.tensor(row['labels']).long())\n","            self.token_list.append(torch.from_numpy(numpy.array( json.loads(row['data']) ) ).long())\n","\n","    def __getitem__(self, index):\n","        return self.token_list[index], self.label_list[index]#, self.token_positions\n","\n","    def __len__(self):\n","        return len(self.label_list)\n","    \n","\n","##%%\n","\n","ratingData = RatingData('../../DataSets/yf_dianping',\n","                             word2index = word2index,\n","                            #  max_row= 5,\n","                             isTrain=True,\n","                             trainTestRate = 0.8,\n","                             wordCuter= jieba,\n","                             clean_file_name='balance_data_4_HAN_original_balance.csv',\n","                             # clean_file_name='balance_data_4_HAN_TWV.csv',\n","                             )\n","trainLoader = torch.utils.data.DataLoader(dataset=ratingData,\n","                                          batch_size=512,\n","                                          shuffle = True,\n","                                          # num_workers = 8,\n","                                          )\n","ratingData2 = RatingData('../../DataSets/yf_dianping',\n","                             word2index = word2index,\n","                             # max_row= 200000,\n","                             isTrain=False,\n","                             trainTestRate = 0.8,\n","                             wordCuter= jieba,\n","                             clean_file_name='balance_data_4_HAN_original_balance.csv',\n","                             # clean_file_name='balance_data_4_HAN_TWV.csv',\n","                             )\n","testLoader = torch.utils.data.DataLoader(dataset=ratingData2,\n","                                          batch_size=128,\n","                                          shuffle = True,\n","                                          # num_workers = 8,\n","                                          )\n","print(len(ratingData.label_list))\n","print(len(ratingData2.label_list))\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":[" balance_data.csv 所在path: ../../DataSets/yf_dianping\n"," balance_data.csv 所在path: ../../DataSets/yf_dianping\n","530311\n","132578\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uxwtXncXqESB","colab_type":"text"},"source":["## 创建模型"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"tFUNf2DRnaO_","colab_type":"code","colab":{}},"source":["isPrint = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"pQYgCURnTocn","colab_type":"code","colab":{}},"source":["class SelfAttention(nn.Module):\n","    def __init__(self, num_input):\n","        super(SelfAttention, self).__init__()\n","        self.W = nn.Linear(num_input, num_input)\n","        self.U = nn.Linear(num_input, 1)\n","\n","    def forward(self, x):\n","        if isPrint : print(\"SelfAttention 前 x.shape：\", x.shape)\n","        u = F.tanh(self.W(x))\n","        if isPrint : print(\"--> F.tanh(self.W(x)) 后 u.shape：\", u.shape, \"self.W：\", self.W)\n","        a = F.softmax(self.U(u), dim=1)\n","        if isPrint : print(\"--> F.softmax(self.U(u), dim=1) 后 a.shape：\", a.shape, \"self.U：\", self.U)\n","        res = torch.mul(a, x).sum(dim=1)\n","        if isPrint : print(\"--> torch.mul(a, x).sum(dim=1) 后 res.shape：\", res.shape)\n","        return res\n","\n","\n","class HAN(nn.Module):\n","    def __init__(self, num_embeddings = 5845,\n","                 num_classes = 10,\n","                 num_words = 20,        # 每句话最多多少个词\n","                 num_sentence = 10,     # 一篇文章多少个句子\n","                 embedding_dim = 200,\n","                 hidden_size_gru = 50,\n","                 hidden_size_att = 100,\n","                 ):\n","        super(HAN, self).__init__()\n","\n","        self.num_words = num_words\n","        self.num_sentence = num_sentence\n","        self.embed = nn.Embedding(num_embeddings, embedding_dim, 0)\n","\n","        self.GRU1 = nn.GRU(embedding_dim,\n","                           hidden_size_gru,\n","                           bidirectional=True,  # 双向  Default: ``False``\n","                           batch_first=True,    # : If ``True``, then the input and output tensors are provided as (batch, seq, feature). Default: ``False``\n","                           )\n","        self.self_attention1 = SelfAttention(hidden_size_gru * 2)\n","\n","\n","        self.GRU2 = nn.GRU(hidden_size_gru * 2,\n","                           hidden_size_gru * 2,\n","                           bidirectional=True,  # 双向  Default: ``False``\n","                           batch_first=True,    # : If ``True``, then the input and output tensors are provided as (batch, seq, feature). Default: ``False``\n","                           )\n","        self.self_attention2 = SelfAttention(hidden_size_gru * 4)\n","\n","        self.fc = nn.Linear(hidden_size_gru * 4, num_classes)\n","\n","    def forward(self, x:torch.Tensor, isSentenceSplit:bool=True):\n","        if isPrint : print()\n","        if isPrint : print()\n","        if isPrint : print(\"x:\", x.shape)\n","        if isSentenceSplit:\n","            sentences = []\n","\n","            for i in range(self.num_sentence):\n","                sentence = x[:, i * self.num_words: (i + 1) * self.num_words]\n","                if isPrint : print(\"-> sentence:\", sentence.shape)\n","                sentence = self.embed(sentence)\n","                if isPrint : print(\"-> embed 后 sentence:\", sentence.shape)\n","                sentence, _ = self.GRU1(sentence)\n","                if isPrint : print(\"-> GRU1 后 sentence:\", sentence.shape)\n","                sentence = self.self_attention1(sentence)\n","                if isPrint : print(\"-> self_attention1 后 sentence:\", sentence.shape)\n","                sentences.append(sentence)\n","            sentences = torch.cat(sentences, dim=1)\n","            if isPrint : print()\n","            if isPrint : print(\"-> torch.cat(sentences, dim=1) 后 sentences:\", sentences.shape)\n","            x = sentences.view(sentences.size(0), self.num_sentence, -1)\n","            if isPrint : print(\"-> sentences.view 后 x:\", x.shape)\n","        else:\n","            sentences = self.embed(x)\n","            if isPrint : print(\"-> embed 后 sentences:\", sentences.shape)\n","            sentences, _ = self.GRU1(sentences)\n","            if isPrint : print(\"-> GRU1 后 sentences:\", sentences.shape)\n","            sentences = self.self_attention1(sentences)\n","            if isPrint : print(\"-> self_attention1 后 sentences:\", sentences.shape)\n","            x = sentences\n","        if isPrint : print()\n","        if isPrint : print(\"view2 后 x:\", x.shape)\n","        x, _ = self.GRU2(x)\n","        if isPrint : print(\"GRU2 后 x:\", x.shape)\n","        x = self.self_attention2(x)\n","        if isPrint : print(\"self_attention2 后 x:\", x.shape)\n","        x = self.fc(x)\n","        if isPrint : print(\"fc 后 x:\", x.shape)\n","        return F.softmax(x, dim=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Sg7CUdVnnaPC","colab_type":"code","outputId":"8f65a7be-9e4f-4616-f989-b9e32e45a017","executionInfo":{"status":"ok","timestamp":1588350576386,"user_tz":-480,"elapsed":1165,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["sentences = []\n","for i in range(4):\n","    newSentence = torch.range(i * 8, (i + 1) * 8 - 1).reshape(2,-1)\n","    sentences.append(newSentence)\n","    print(' -> ',newSentence)\n","\n","sentences = torch.cat(sentences)\n","print('sentences ',sentences.size())\n","print('sentences.size(0) ',sentences.size(0))\n","x = sentences.view(sentences.size(0) * 2 , -1)\n","print(\"x\", x, x.shape)\n","# x = sentences.view(sentences.size(0) // 2 , -1)\n","# print(\"x\", x, x.size())\n","# x = sentences.view(x.size(0) * 2 , 2, -1)\n","# print(\"x\", x, x.shape)"],"execution_count":23,"outputs":[{"output_type":"stream","text":[" ->  tensor([[0., 1., 2., 3.],\n","        [4., 5., 6., 7.]])\n"," ->  tensor([[ 8.,  9., 10., 11.],\n","        [12., 13., 14., 15.]])\n"," ->  tensor([[16., 17., 18., 19.],\n","        [20., 21., 22., 23.]])\n"," ->  tensor([[24., 25., 26., 27.],\n","        [28., 29., 30., 31.]])\n","sentences  torch.Size([8, 4])\n","sentences.size(0)  8\n","x tensor([[ 0.,  1.],\n","        [ 2.,  3.],\n","        [ 4.,  5.],\n","        [ 6.,  7.],\n","        [ 8.,  9.],\n","        [10., 11.],\n","        [12., 13.],\n","        [14., 15.],\n","        [16., 17.],\n","        [18., 19.],\n","        [20., 21.],\n","        [22., 23.],\n","        [24., 25.],\n","        [26., 27.],\n","        [28., 29.],\n","        [30., 31.]]) torch.Size([16, 2])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"2uMgphu4naPD","colab_type":"code","outputId":"d56ac849-7b4a-4f77-e290-7c87f0c1cdc2","executionInfo":{"status":"ok","timestamp":1588356074186,"user_tz":-480,"elapsed":5496763,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["isSentenceSplit = True\n","\n","#创建模型\n","wordEmbedding = torch.FloatTensor(wordEmbedding)\n","num_embeddings = len(word2vec.wv.index2word)\n","# Classical\n","model = HAN(num_embeddings,\n","            num_classes = 3,\n","            embedding_dim = word2vec.wv.vector_size,\n","            num_words = 10,\n","            num_sentence = 10,\n","            hidden_size_gru = 512,\n","            hidden_size_att = 768,\n","            )\n","# model = HAN(num_embeddings,\n","#             num_classes = 3,\n","#             embedding_dim = word2vec.wv.vector_size,\n","#             num_words = 100,\n","#             hidden_size_gru = 200,\n","#             hidden_size_att = 400,\n","#             )\n","print(model)\n","\n","modelParams = model.parameters()\n","for param in modelParams:\n","    if len(param.data.shape) > 1:\n","        # print('---', param.data.shape, param.data)\n","        torch.nn.init.kaiming_normal(param.data)\n","        # print('--->', param.data)\n","        \n","model.embed.from_pretrained(wordEmbedding)\n","\n","\n","##%% md\n","\n","## 开始训练过程\n","\n","##%%\n","\n","def trainOneEpoch(epoch, model:HAN, trainLoader, optimizer:Optimizer, lossFunc):\n","    if torch.cuda.is_available():\n","        model = model.cuda()\n","        lossFunc = lossFunc.cuda()\n","\n","    model.train()\n","\n","    startTime = time.time()\n","    for i, (x, y) in enumerate(trainLoader):\n","        if torch.cuda.is_available():\n","            x = x.cuda()\n","            y = y.cuda()\n","\n","        outputs = model(x, isSentenceSplit)\n","        loss = lossFunc(outputs, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 100 == 99:\n","            print('Epoch %d, %d/%d, loss:%f ' % (epoch, i, len(trainLoader), loss))\n","        # if i > 2000:\n","        #     break \n","    print('Epoch %d cost time: %.3fs' % (epoch, time.time() - startTime))\n","\n","\n","def testModel(epoch, model:HAN, testLoader):\n","    if torch.cuda.is_available():\n","        model = model.cuda()\n","\n","    model.eval()\n","\n","    total = 0\n","    correct = 0\n","\n","    startTime = time.time()\n","    for i, (x, y) in enumerate(testLoader):\n","        if torch.cuda.is_available():\n","            x = x.cuda()\n","            y = y.cuda()\n","\n","        outputs = model(x, isSentenceSplit)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total += len(y)\n","        correct += predicted.data.eq(y.data).cpu().sum().numpy()\n","        \n","\n","        if i % 50 == 49:\n","            print('Epoch Test %d, %d/%d' % (epoch, i, len(testLoader)))\n","        # if i > 2000:\n","        #     break \n","    print('Epoch Test %d cost time: %.3fs' % (epoch, time.time() - startTime))\n","    print('准确率： %.3f' % (correct / total))\n","    return correct / total\n","\n","\n","def train(epoch, model, modelSavePath, isLoad, lr=0.0002):\n","    last_acc = 0\n","    if isLoad: \n","        model.load_state_dict(torch.load(modelSavePath))\n","        last_acc = testModel(epoch, model, testLoader)\n","    # optimizer=torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.001)\n","    optimizer=torch.optim.Adam(model.parameters(), lr=0.0002)\n","    lossFunc =torch.nn.CrossEntropyLoss()\n","    for epoch in range(epoch):\n","        trainOneEpoch(epoch, model, trainLoader, optimizer, lossFunc)\n","        acc = testModel(epoch, model, testLoader)\n","        if last_acc < acc:\n","          torch.save(model.state_dict(), modelSavePath)\n","        last_acc = acc\n","\n","train(20, model, 'EmotionAnalyzeModelData_ClassicalHAN_OB_plus.model', False, lr=0.001)\n","    "],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"stream","text":["HAN(\n","  (embed): Embedding(99999, 200, padding_idx=0)\n","  (GRU1): GRU(200, 512, batch_first=True, bidirectional=True)\n","  (self_attention1): SelfAttention(\n","    (W): Linear(in_features=1024, out_features=1024, bias=True)\n","    (U): Linear(in_features=1024, out_features=1, bias=True)\n","  )\n","  (GRU2): GRU(1024, 1024, batch_first=True, bidirectional=True)\n","  (self_attention2): SelfAttention(\n","    (W): Linear(in_features=2048, out_features=2048, bias=True)\n","    (U): Linear(in_features=2048, out_features=1, bias=True)\n","  )\n","  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 0, 99/1036, loss:0.921697 \n","Epoch 0, 199/1036, loss:0.881506 \n","Epoch 0, 299/1036, loss:0.924276 \n","Epoch 0, 399/1036, loss:0.922538 \n","Epoch 0, 499/1036, loss:0.901450 \n","Epoch 0, 599/1036, loss:0.888400 \n","Epoch 0, 699/1036, loss:0.902076 \n","Epoch 0, 799/1036, loss:0.879344 \n","Epoch 0, 899/1036, loss:0.886001 \n","Epoch 0, 999/1036, loss:0.882738 \n","Epoch 0 cost time: 248.523s\n","Epoch Test 0, 49/1036\n","Epoch Test 0, 99/1036\n","Epoch Test 0, 149/1036\n","Epoch Test 0, 199/1036\n","Epoch Test 0, 249/1036\n","Epoch Test 0, 299/1036\n","Epoch Test 0, 349/1036\n","Epoch Test 0, 399/1036\n","Epoch Test 0, 449/1036\n","Epoch Test 0, 499/1036\n","Epoch Test 0, 549/1036\n","Epoch Test 0, 599/1036\n","Epoch Test 0, 649/1036\n","Epoch Test 0, 699/1036\n","Epoch Test 0, 749/1036\n","Epoch Test 0, 799/1036\n","Epoch Test 0, 849/1036\n","Epoch Test 0, 899/1036\n","Epoch Test 0, 949/1036\n","Epoch Test 0, 999/1036\n","Epoch Test 0 cost time: 25.588s\n","准确率： 0.652\n","Epoch 1, 99/1036, loss:0.829877 \n","Epoch 1, 199/1036, loss:0.864588 \n","Epoch 1, 299/1036, loss:0.895979 \n","Epoch 1, 399/1036, loss:0.868945 \n","Epoch 1, 499/1036, loss:0.850326 \n","Epoch 1, 599/1036, loss:0.880709 \n","Epoch 1, 699/1036, loss:0.879700 \n","Epoch 1, 799/1036, loss:0.888974 \n","Epoch 1, 899/1036, loss:0.884429 \n","Epoch 1, 999/1036, loss:0.893097 \n","Epoch 1 cost time: 248.635s\n","Epoch Test 1, 49/1036\n","Epoch Test 1, 99/1036\n","Epoch Test 1, 149/1036\n","Epoch Test 1, 199/1036\n","Epoch Test 1, 249/1036\n","Epoch Test 1, 299/1036\n","Epoch Test 1, 349/1036\n","Epoch Test 1, 399/1036\n","Epoch Test 1, 449/1036\n","Epoch Test 1, 499/1036\n","Epoch Test 1, 549/1036\n","Epoch Test 1, 599/1036\n","Epoch Test 1, 649/1036\n","Epoch Test 1, 699/1036\n","Epoch Test 1, 749/1036\n","Epoch Test 1, 799/1036\n","Epoch Test 1, 849/1036\n","Epoch Test 1, 899/1036\n","Epoch Test 1, 949/1036\n","Epoch Test 1, 999/1036\n","Epoch Test 1 cost time: 25.578s\n","准确率： 0.680\n","Epoch 2, 99/1036, loss:0.857585 \n","Epoch 2, 199/1036, loss:0.838517 \n","Epoch 2, 299/1036, loss:0.880455 \n","Epoch 2, 399/1036, loss:0.842477 \n","Epoch 2, 499/1036, loss:0.812196 \n","Epoch 2, 599/1036, loss:0.898222 \n","Epoch 2, 699/1036, loss:0.885637 \n","Epoch 2, 799/1036, loss:0.844215 \n","Epoch 2, 899/1036, loss:0.874555 \n","Epoch 2, 999/1036, loss:0.828396 \n","Epoch 2 cost time: 248.630s\n","Epoch Test 2, 49/1036\n","Epoch Test 2, 99/1036\n","Epoch Test 2, 149/1036\n","Epoch Test 2, 199/1036\n","Epoch Test 2, 249/1036\n","Epoch Test 2, 299/1036\n","Epoch Test 2, 349/1036\n","Epoch Test 2, 399/1036\n","Epoch Test 2, 449/1036\n","Epoch Test 2, 499/1036\n","Epoch Test 2, 549/1036\n","Epoch Test 2, 599/1036\n","Epoch Test 2, 649/1036\n","Epoch Test 2, 699/1036\n","Epoch Test 2, 749/1036\n","Epoch Test 2, 799/1036\n","Epoch Test 2, 849/1036\n","Epoch Test 2, 899/1036\n","Epoch Test 2, 949/1036\n","Epoch Test 2, 999/1036\n","Epoch Test 2 cost time: 25.591s\n","准确率： 0.695\n","Epoch 3, 99/1036, loss:0.803146 \n","Epoch 3, 199/1036, loss:0.836586 \n","Epoch 3, 299/1036, loss:0.845626 \n","Epoch 3, 399/1036, loss:0.835789 \n","Epoch 3, 499/1036, loss:0.853399 \n","Epoch 3, 599/1036, loss:0.835215 \n","Epoch 3, 699/1036, loss:0.846966 \n","Epoch 3, 799/1036, loss:0.827824 \n","Epoch 3, 899/1036, loss:0.849483 \n","Epoch 3, 999/1036, loss:0.883367 \n","Epoch 3 cost time: 248.805s\n","Epoch Test 3, 49/1036\n","Epoch Test 3, 99/1036\n","Epoch Test 3, 149/1036\n","Epoch Test 3, 199/1036\n","Epoch Test 3, 249/1036\n","Epoch Test 3, 299/1036\n","Epoch Test 3, 349/1036\n","Epoch Test 3, 399/1036\n","Epoch Test 3, 449/1036\n","Epoch Test 3, 499/1036\n","Epoch Test 3, 549/1036\n","Epoch Test 3, 599/1036\n","Epoch Test 3, 649/1036\n","Epoch Test 3, 699/1036\n","Epoch Test 3, 749/1036\n","Epoch Test 3, 799/1036\n","Epoch Test 3, 849/1036\n","Epoch Test 3, 899/1036\n","Epoch Test 3, 949/1036\n","Epoch Test 3, 999/1036\n","Epoch Test 3 cost time: 25.582s\n","准确率： 0.704\n","Epoch 4, 99/1036, loss:0.841732 \n","Epoch 4, 199/1036, loss:0.824715 \n","Epoch 4, 299/1036, loss:0.848272 \n","Epoch 4, 399/1036, loss:0.794400 \n","Epoch 4, 499/1036, loss:0.809032 \n","Epoch 4, 599/1036, loss:0.826506 \n","Epoch 4, 699/1036, loss:0.831841 \n","Epoch 4, 799/1036, loss:0.827103 \n","Epoch 4, 899/1036, loss:0.804516 \n","Epoch 4, 999/1036, loss:0.838722 \n","Epoch 4 cost time: 248.755s\n","Epoch Test 4, 49/1036\n","Epoch Test 4, 99/1036\n","Epoch Test 4, 149/1036\n","Epoch Test 4, 199/1036\n","Epoch Test 4, 249/1036\n","Epoch Test 4, 299/1036\n","Epoch Test 4, 349/1036\n","Epoch Test 4, 399/1036\n","Epoch Test 4, 449/1036\n","Epoch Test 4, 499/1036\n","Epoch Test 4, 549/1036\n","Epoch Test 4, 599/1036\n","Epoch Test 4, 649/1036\n","Epoch Test 4, 699/1036\n","Epoch Test 4, 749/1036\n","Epoch Test 4, 799/1036\n","Epoch Test 4, 849/1036\n","Epoch Test 4, 899/1036\n","Epoch Test 4, 949/1036\n","Epoch Test 4, 999/1036\n","Epoch Test 4 cost time: 25.591s\n","准确率： 0.716\n","Epoch 5, 99/1036, loss:0.820754 \n","Epoch 5, 199/1036, loss:0.804816 \n","Epoch 5, 299/1036, loss:0.805371 \n","Epoch 5, 399/1036, loss:0.833671 \n","Epoch 5, 499/1036, loss:0.803991 \n","Epoch 5, 599/1036, loss:0.803938 \n","Epoch 5, 699/1036, loss:0.793743 \n","Epoch 5, 799/1036, loss:0.814148 \n","Epoch 5, 899/1036, loss:0.834987 \n","Epoch 5, 999/1036, loss:0.810542 \n","Epoch 5 cost time: 248.577s\n","Epoch Test 5, 49/1036\n","Epoch Test 5, 99/1036\n","Epoch Test 5, 149/1036\n","Epoch Test 5, 199/1036\n","Epoch Test 5, 249/1036\n","Epoch Test 5, 299/1036\n","Epoch Test 5, 349/1036\n","Epoch Test 5, 399/1036\n","Epoch Test 5, 449/1036\n","Epoch Test 5, 499/1036\n","Epoch Test 5, 549/1036\n","Epoch Test 5, 599/1036\n","Epoch Test 5, 649/1036\n","Epoch Test 5, 699/1036\n","Epoch Test 5, 749/1036\n","Epoch Test 5, 799/1036\n","Epoch Test 5, 849/1036\n","Epoch Test 5, 899/1036\n","Epoch Test 5, 949/1036\n","Epoch Test 5, 999/1036\n","Epoch Test 5 cost time: 25.613s\n","准确率： 0.724\n","Epoch 6, 99/1036, loss:0.787474 \n","Epoch 6, 199/1036, loss:0.792514 \n","Epoch 6, 299/1036, loss:0.769953 \n","Epoch 6, 399/1036, loss:0.819819 \n","Epoch 6, 499/1036, loss:0.793170 \n","Epoch 6, 599/1036, loss:0.793874 \n","Epoch 6, 699/1036, loss:0.808555 \n","Epoch 6, 799/1036, loss:0.781234 \n","Epoch 6, 899/1036, loss:0.802245 \n","Epoch 6, 999/1036, loss:0.801975 \n","Epoch 6 cost time: 248.684s\n","Epoch Test 6, 49/1036\n","Epoch Test 6, 99/1036\n","Epoch Test 6, 149/1036\n","Epoch Test 6, 199/1036\n","Epoch Test 6, 249/1036\n","Epoch Test 6, 299/1036\n","Epoch Test 6, 349/1036\n","Epoch Test 6, 399/1036\n","Epoch Test 6, 449/1036\n","Epoch Test 6, 499/1036\n","Epoch Test 6, 549/1036\n","Epoch Test 6, 599/1036\n","Epoch Test 6, 649/1036\n","Epoch Test 6, 699/1036\n","Epoch Test 6, 749/1036\n","Epoch Test 6, 799/1036\n","Epoch Test 6, 849/1036\n","Epoch Test 6, 899/1036\n","Epoch Test 6, 949/1036\n","Epoch Test 6, 999/1036\n","Epoch Test 6 cost time: 25.619s\n","准确率： 0.734\n","Epoch 7, 99/1036, loss:0.770831 \n","Epoch 7, 199/1036, loss:0.780007 \n","Epoch 7, 299/1036, loss:0.767240 \n","Epoch 7, 399/1036, loss:0.802485 \n","Epoch 7, 499/1036, loss:0.789786 \n","Epoch 7, 599/1036, loss:0.789033 \n","Epoch 7, 699/1036, loss:0.801224 \n","Epoch 7, 799/1036, loss:0.790668 \n","Epoch 7, 899/1036, loss:0.802318 \n","Epoch 7, 999/1036, loss:0.815841 \n","Epoch 7 cost time: 248.638s\n","Epoch Test 7, 49/1036\n","Epoch Test 7, 99/1036\n","Epoch Test 7, 149/1036\n","Epoch Test 7, 199/1036\n","Epoch Test 7, 249/1036\n","Epoch Test 7, 299/1036\n","Epoch Test 7, 349/1036\n","Epoch Test 7, 399/1036\n","Epoch Test 7, 449/1036\n","Epoch Test 7, 499/1036\n","Epoch Test 7, 549/1036\n","Epoch Test 7, 599/1036\n","Epoch Test 7, 649/1036\n","Epoch Test 7, 699/1036\n","Epoch Test 7, 749/1036\n","Epoch Test 7, 799/1036\n","Epoch Test 7, 849/1036\n","Epoch Test 7, 899/1036\n","Epoch Test 7, 949/1036\n","Epoch Test 7, 999/1036\n","Epoch Test 7 cost time: 25.618s\n","准确率： 0.735\n","Epoch 8, 99/1036, loss:0.748602 \n","Epoch 8, 199/1036, loss:0.802116 \n","Epoch 8, 299/1036, loss:0.802033 \n","Epoch 8, 399/1036, loss:0.801939 \n","Epoch 8, 499/1036, loss:0.780504 \n","Epoch 8, 599/1036, loss:0.770601 \n","Epoch 8, 699/1036, loss:0.789441 \n","Epoch 8, 799/1036, loss:0.814424 \n","Epoch 8, 899/1036, loss:0.782879 \n","Epoch 8, 999/1036, loss:0.780849 \n","Epoch 8 cost time: 248.586s\n","Epoch Test 8, 49/1036\n","Epoch Test 8, 99/1036\n","Epoch Test 8, 149/1036\n","Epoch Test 8, 199/1036\n","Epoch Test 8, 249/1036\n","Epoch Test 8, 299/1036\n","Epoch Test 8, 349/1036\n","Epoch Test 8, 399/1036\n","Epoch Test 8, 449/1036\n","Epoch Test 8, 499/1036\n","Epoch Test 8, 549/1036\n","Epoch Test 8, 599/1036\n","Epoch Test 8, 649/1036\n","Epoch Test 8, 699/1036\n","Epoch Test 8, 749/1036\n","Epoch Test 8, 799/1036\n","Epoch Test 8, 849/1036\n","Epoch Test 8, 899/1036\n","Epoch Test 8, 949/1036\n","Epoch Test 8, 999/1036\n","Epoch Test 8 cost time: 25.498s\n","准确率： 0.745\n","Epoch 9, 99/1036, loss:0.793285 \n","Epoch 9, 199/1036, loss:0.789179 \n","Epoch 9, 299/1036, loss:0.790091 \n","Epoch 9, 399/1036, loss:0.773062 \n","Epoch 9, 499/1036, loss:0.728368 \n","Epoch 9, 599/1036, loss:0.778945 \n","Epoch 9, 699/1036, loss:0.824025 \n","Epoch 9, 799/1036, loss:0.762417 \n","Epoch 9, 899/1036, loss:0.782644 \n","Epoch 9, 999/1036, loss:0.782871 \n","Epoch 9 cost time: 248.659s\n","Epoch Test 9, 49/1036\n","Epoch Test 9, 99/1036\n","Epoch Test 9, 149/1036\n","Epoch Test 9, 199/1036\n","Epoch Test 9, 249/1036\n","Epoch Test 9, 299/1036\n","Epoch Test 9, 349/1036\n","Epoch Test 9, 399/1036\n","Epoch Test 9, 449/1036\n","Epoch Test 9, 499/1036\n","Epoch Test 9, 549/1036\n","Epoch Test 9, 599/1036\n","Epoch Test 9, 649/1036\n","Epoch Test 9, 699/1036\n","Epoch Test 9, 749/1036\n","Epoch Test 9, 799/1036\n","Epoch Test 9, 849/1036\n","Epoch Test 9, 899/1036\n","Epoch Test 9, 949/1036\n","Epoch Test 9, 999/1036\n","Epoch Test 9 cost time: 25.648s\n","准确率： 0.750\n","Epoch 10, 99/1036, loss:0.791379 \n","Epoch 10, 199/1036, loss:0.775479 \n","Epoch 10, 299/1036, loss:0.742281 \n","Epoch 10, 399/1036, loss:0.750703 \n","Epoch 10, 499/1036, loss:0.767519 \n","Epoch 10, 599/1036, loss:0.801050 \n","Epoch 10, 699/1036, loss:0.783526 \n","Epoch 10, 799/1036, loss:0.784983 \n","Epoch 10, 899/1036, loss:0.792200 \n","Epoch 10, 999/1036, loss:0.782023 \n","Epoch 10 cost time: 248.618s\n","Epoch Test 10, 49/1036\n","Epoch Test 10, 99/1036\n","Epoch Test 10, 149/1036\n","Epoch Test 10, 199/1036\n","Epoch Test 10, 249/1036\n","Epoch Test 10, 299/1036\n","Epoch Test 10, 349/1036\n","Epoch Test 10, 399/1036\n","Epoch Test 10, 449/1036\n","Epoch Test 10, 499/1036\n","Epoch Test 10, 549/1036\n","Epoch Test 10, 599/1036\n","Epoch Test 10, 649/1036\n","Epoch Test 10, 699/1036\n","Epoch Test 10, 749/1036\n","Epoch Test 10, 799/1036\n","Epoch Test 10, 849/1036\n","Epoch Test 10, 899/1036\n","Epoch Test 10, 949/1036\n","Epoch Test 10, 999/1036\n","Epoch Test 10 cost time: 25.629s\n","准确率： 0.754\n","Epoch 11, 99/1036, loss:0.779935 \n","Epoch 11, 199/1036, loss:0.796300 \n","Epoch 11, 299/1036, loss:0.761434 \n","Epoch 11, 399/1036, loss:0.772114 \n","Epoch 11, 499/1036, loss:0.747903 \n","Epoch 11, 599/1036, loss:0.783900 \n","Epoch 11, 699/1036, loss:0.760320 \n","Epoch 11, 799/1036, loss:0.755714 \n","Epoch 11, 899/1036, loss:0.761221 \n","Epoch 11, 999/1036, loss:0.778496 \n","Epoch 11 cost time: 248.663s\n","Epoch Test 11, 49/1036\n","Epoch Test 11, 99/1036\n","Epoch Test 11, 149/1036\n","Epoch Test 11, 199/1036\n","Epoch Test 11, 249/1036\n","Epoch Test 11, 299/1036\n","Epoch Test 11, 349/1036\n","Epoch Test 11, 399/1036\n","Epoch Test 11, 449/1036\n","Epoch Test 11, 499/1036\n","Epoch Test 11, 549/1036\n","Epoch Test 11, 599/1036\n","Epoch Test 11, 649/1036\n","Epoch Test 11, 699/1036\n","Epoch Test 11, 749/1036\n","Epoch Test 11, 799/1036\n","Epoch Test 11, 849/1036\n","Epoch Test 11, 899/1036\n","Epoch Test 11, 949/1036\n","Epoch Test 11, 999/1036\n","Epoch Test 11 cost time: 25.728s\n","准确率： 0.756\n","Epoch 12, 99/1036, loss:0.781951 \n","Epoch 12, 199/1036, loss:0.753380 \n","Epoch 12, 299/1036, loss:0.748618 \n","Epoch 12, 399/1036, loss:0.771830 \n","Epoch 12, 499/1036, loss:0.748623 \n","Epoch 12, 599/1036, loss:0.775513 \n","Epoch 12, 699/1036, loss:0.744310 \n","Epoch 12, 799/1036, loss:0.754199 \n","Epoch 12, 899/1036, loss:0.757697 \n","Epoch 12, 999/1036, loss:0.771617 \n","Epoch 12 cost time: 248.632s\n","Epoch Test 12, 49/1036\n","Epoch Test 12, 99/1036\n","Epoch Test 12, 149/1036\n","Epoch Test 12, 199/1036\n","Epoch Test 12, 249/1036\n","Epoch Test 12, 299/1036\n","Epoch Test 12, 349/1036\n","Epoch Test 12, 399/1036\n","Epoch Test 12, 449/1036\n","Epoch Test 12, 499/1036\n","Epoch Test 12, 549/1036\n","Epoch Test 12, 599/1036\n","Epoch Test 12, 649/1036\n","Epoch Test 12, 699/1036\n","Epoch Test 12, 749/1036\n","Epoch Test 12, 799/1036\n","Epoch Test 12, 849/1036\n","Epoch Test 12, 899/1036\n","Epoch Test 12, 949/1036\n","Epoch Test 12, 999/1036\n","Epoch Test 12 cost time: 25.636s\n","准确率： 0.760\n","Epoch 13, 99/1036, loss:0.764297 \n","Epoch 13, 199/1036, loss:0.735748 \n","Epoch 13, 299/1036, loss:0.756119 \n","Epoch 13, 399/1036, loss:0.753797 \n","Epoch 13, 499/1036, loss:0.770523 \n","Epoch 13, 599/1036, loss:0.735400 \n","Epoch 13, 699/1036, loss:0.754033 \n","Epoch 13, 799/1036, loss:0.750577 \n","Epoch 13, 899/1036, loss:0.755012 \n","Epoch 13, 999/1036, loss:0.766289 \n","Epoch 13 cost time: 248.636s\n","Epoch Test 13, 49/1036\n","Epoch Test 13, 99/1036\n","Epoch Test 13, 149/1036\n","Epoch Test 13, 199/1036\n","Epoch Test 13, 249/1036\n","Epoch Test 13, 299/1036\n","Epoch Test 13, 349/1036\n","Epoch Test 13, 399/1036\n","Epoch Test 13, 449/1036\n","Epoch Test 13, 499/1036\n","Epoch Test 13, 549/1036\n","Epoch Test 13, 599/1036\n","Epoch Test 13, 649/1036\n","Epoch Test 13, 699/1036\n","Epoch Test 13, 749/1036\n","Epoch Test 13, 799/1036\n","Epoch Test 13, 849/1036\n","Epoch Test 13, 899/1036\n","Epoch Test 13, 949/1036\n","Epoch Test 13, 999/1036\n","Epoch Test 13 cost time: 25.628s\n","准确率： 0.763\n","Epoch 14, 99/1036, loss:0.752731 \n","Epoch 14, 199/1036, loss:0.754092 \n","Epoch 14, 299/1036, loss:0.738634 \n","Epoch 14, 399/1036, loss:0.764946 \n","Epoch 14, 499/1036, loss:0.760216 \n","Epoch 14, 599/1036, loss:0.755919 \n","Epoch 14, 699/1036, loss:0.737824 \n","Epoch 14, 799/1036, loss:0.738858 \n","Epoch 14, 899/1036, loss:0.745368 \n","Epoch 14, 999/1036, loss:0.767242 \n","Epoch 14 cost time: 248.857s\n","Epoch Test 14, 49/1036\n","Epoch Test 14, 99/1036\n","Epoch Test 14, 149/1036\n","Epoch Test 14, 199/1036\n","Epoch Test 14, 249/1036\n","Epoch Test 14, 299/1036\n","Epoch Test 14, 349/1036\n","Epoch Test 14, 399/1036\n","Epoch Test 14, 449/1036\n","Epoch Test 14, 499/1036\n","Epoch Test 14, 549/1036\n","Epoch Test 14, 599/1036\n","Epoch Test 14, 649/1036\n","Epoch Test 14, 699/1036\n","Epoch Test 14, 749/1036\n","Epoch Test 14, 799/1036\n","Epoch Test 14, 849/1036\n","Epoch Test 14, 899/1036\n","Epoch Test 14, 949/1036\n","Epoch Test 14, 999/1036\n","Epoch Test 14 cost time: 25.644s\n","准确率： 0.766\n","Epoch 15, 99/1036, loss:0.758399 \n","Epoch 15, 199/1036, loss:0.757678 \n","Epoch 15, 299/1036, loss:0.731335 \n","Epoch 15, 399/1036, loss:0.736758 \n","Epoch 15, 499/1036, loss:0.798763 \n","Epoch 15, 599/1036, loss:0.763855 \n","Epoch 15, 699/1036, loss:0.774951 \n","Epoch 15, 799/1036, loss:0.774449 \n","Epoch 15, 899/1036, loss:0.760894 \n","Epoch 15, 999/1036, loss:0.750304 \n","Epoch 15 cost time: 248.559s\n","Epoch Test 15, 49/1036\n","Epoch Test 15, 99/1036\n","Epoch Test 15, 149/1036\n","Epoch Test 15, 199/1036\n","Epoch Test 15, 249/1036\n","Epoch Test 15, 299/1036\n","Epoch Test 15, 349/1036\n","Epoch Test 15, 399/1036\n","Epoch Test 15, 449/1036\n","Epoch Test 15, 499/1036\n","Epoch Test 15, 549/1036\n","Epoch Test 15, 599/1036\n","Epoch Test 15, 649/1036\n","Epoch Test 15, 699/1036\n","Epoch Test 15, 749/1036\n","Epoch Test 15, 799/1036\n","Epoch Test 15, 849/1036\n","Epoch Test 15, 899/1036\n","Epoch Test 15, 949/1036\n","Epoch Test 15, 999/1036\n","Epoch Test 15 cost time: 25.622s\n","准确率： 0.767\n","Epoch 16, 99/1036, loss:0.736879 \n","Epoch 16, 199/1036, loss:0.751132 \n","Epoch 16, 299/1036, loss:0.741367 \n","Epoch 16, 399/1036, loss:0.755642 \n","Epoch 16, 499/1036, loss:0.755268 \n","Epoch 16, 599/1036, loss:0.721487 \n","Epoch 16, 699/1036, loss:0.767264 \n","Epoch 16, 799/1036, loss:0.767955 \n","Epoch 16, 899/1036, loss:0.737967 \n","Epoch 16, 999/1036, loss:0.778011 \n","Epoch 16 cost time: 248.597s\n","Epoch Test 16, 49/1036\n","Epoch Test 16, 99/1036\n","Epoch Test 16, 149/1036\n","Epoch Test 16, 199/1036\n","Epoch Test 16, 249/1036\n","Epoch Test 16, 299/1036\n","Epoch Test 16, 349/1036\n","Epoch Test 16, 399/1036\n","Epoch Test 16, 449/1036\n","Epoch Test 16, 499/1036\n","Epoch Test 16, 549/1036\n","Epoch Test 16, 599/1036\n","Epoch Test 16, 649/1036\n","Epoch Test 16, 699/1036\n","Epoch Test 16, 749/1036\n","Epoch Test 16, 799/1036\n","Epoch Test 16, 849/1036\n","Epoch Test 16, 899/1036\n","Epoch Test 16, 949/1036\n","Epoch Test 16, 999/1036\n","Epoch Test 16 cost time: 25.637s\n","准确率： 0.769\n","Epoch 17, 99/1036, loss:0.747062 \n","Epoch 17, 199/1036, loss:0.774026 \n","Epoch 17, 299/1036, loss:0.733059 \n","Epoch 17, 399/1036, loss:0.728342 \n","Epoch 17, 499/1036, loss:0.770444 \n","Epoch 17, 599/1036, loss:0.738404 \n","Epoch 17, 699/1036, loss:0.748993 \n","Epoch 17, 799/1036, loss:0.734882 \n","Epoch 17, 899/1036, loss:0.734137 \n","Epoch 17, 999/1036, loss:0.736717 \n","Epoch 17 cost time: 248.555s\n","Epoch Test 17, 49/1036\n","Epoch Test 17, 99/1036\n","Epoch Test 17, 149/1036\n","Epoch Test 17, 199/1036\n","Epoch Test 17, 249/1036\n","Epoch Test 17, 299/1036\n","Epoch Test 17, 349/1036\n","Epoch Test 17, 399/1036\n","Epoch Test 17, 449/1036\n","Epoch Test 17, 499/1036\n","Epoch Test 17, 549/1036\n","Epoch Test 17, 599/1036\n","Epoch Test 17, 649/1036\n","Epoch Test 17, 699/1036\n","Epoch Test 17, 749/1036\n","Epoch Test 17, 799/1036\n","Epoch Test 17, 849/1036\n","Epoch Test 17, 899/1036\n","Epoch Test 17, 949/1036\n","Epoch Test 17, 999/1036\n","Epoch Test 17 cost time: 25.630s\n","准确率： 0.771\n","Epoch 18, 99/1036, loss:0.731237 \n","Epoch 18, 199/1036, loss:0.741142 \n","Epoch 18, 299/1036, loss:0.732273 \n","Epoch 18, 399/1036, loss:0.754219 \n","Epoch 18, 499/1036, loss:0.750242 \n","Epoch 18, 599/1036, loss:0.745401 \n","Epoch 18, 699/1036, loss:0.749879 \n","Epoch 18, 799/1036, loss:0.755032 \n","Epoch 18, 899/1036, loss:0.746596 \n","Epoch 18, 999/1036, loss:0.751698 \n","Epoch 18 cost time: 248.569s\n","Epoch Test 18, 49/1036\n","Epoch Test 18, 99/1036\n","Epoch Test 18, 149/1036\n","Epoch Test 18, 199/1036\n","Epoch Test 18, 249/1036\n","Epoch Test 18, 299/1036\n","Epoch Test 18, 349/1036\n","Epoch Test 18, 399/1036\n","Epoch Test 18, 449/1036\n","Epoch Test 18, 499/1036\n","Epoch Test 18, 549/1036\n","Epoch Test 18, 599/1036\n","Epoch Test 18, 649/1036\n","Epoch Test 18, 699/1036\n","Epoch Test 18, 749/1036\n","Epoch Test 18, 799/1036\n","Epoch Test 18, 849/1036\n","Epoch Test 18, 899/1036\n","Epoch Test 18, 949/1036\n","Epoch Test 18, 999/1036\n","Epoch Test 18 cost time: 25.643s\n","准确率： 0.773\n","Epoch 19, 99/1036, loss:0.754812 \n","Epoch 19, 199/1036, loss:0.750092 \n","Epoch 19, 299/1036, loss:0.723517 \n","Epoch 19, 399/1036, loss:0.768851 \n","Epoch 19, 499/1036, loss:0.743292 \n","Epoch 19, 599/1036, loss:0.750438 \n","Epoch 19, 699/1036, loss:0.727731 \n","Epoch 19, 799/1036, loss:0.741990 \n","Epoch 19, 899/1036, loss:0.730306 \n","Epoch 19, 999/1036, loss:0.756898 \n","Epoch 19 cost time: 248.593s\n","Epoch Test 19, 49/1036\n","Epoch Test 19, 99/1036\n","Epoch Test 19, 149/1036\n","Epoch Test 19, 199/1036\n","Epoch Test 19, 249/1036\n","Epoch Test 19, 299/1036\n","Epoch Test 19, 349/1036\n","Epoch Test 19, 399/1036\n","Epoch Test 19, 449/1036\n","Epoch Test 19, 499/1036\n","Epoch Test 19, 549/1036\n","Epoch Test 19, 599/1036\n","Epoch Test 19, 649/1036\n","Epoch Test 19, 699/1036\n","Epoch Test 19, 749/1036\n","Epoch Test 19, 799/1036\n","Epoch Test 19, 849/1036\n","Epoch Test 19, 899/1036\n","Epoch Test 19, 949/1036\n","Epoch Test 19, 999/1036\n","Epoch Test 19 cost time: 25.667s\n","准确率： 0.773\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"IgjQbdtsnaPF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"_N1cAYSInaPH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9a96b61f-0a13-41c8-ef05-8edd350b18da","executionInfo":{"status":"ok","timestamp":1588367114120,"user_tz":-480,"elapsed":15906155,"user":{"displayName":"fuliu fuliu","photoUrl":"","userId":"17240005970423735187"}}},"source":["train(20, model, 'EmotionAnalyzeModelData_ClassicalHAN_OB_plus.model', True, lr=0.0003)\n","train(20, model, 'EmotionAnalyzeModelData_ClassicalHAN_OB_plus.model', True, lr=0.0001)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch Test 20, 49/1036\n","Epoch Test 20, 99/1036\n","Epoch Test 20, 149/1036\n","Epoch Test 20, 199/1036\n","Epoch Test 20, 249/1036\n","Epoch Test 20, 299/1036\n","Epoch Test 20, 349/1036\n","Epoch Test 20, 399/1036\n","Epoch Test 20, 449/1036\n","Epoch Test 20, 499/1036\n","Epoch Test 20, 549/1036\n","Epoch Test 20, 599/1036\n","Epoch Test 20, 649/1036\n","Epoch Test 20, 699/1036\n","Epoch Test 20, 749/1036\n","Epoch Test 20, 799/1036\n","Epoch Test 20, 849/1036\n","Epoch Test 20, 899/1036\n","Epoch Test 20, 949/1036\n","Epoch Test 20, 999/1036\n","Epoch Test 20 cost time: 25.609s\n","准确率： 0.773\n","Epoch 0, 99/1036, loss:0.749782 \n","Epoch 0, 199/1036, loss:0.745405 \n","Epoch 0, 299/1036, loss:0.742819 \n","Epoch 0, 399/1036, loss:0.761922 \n","Epoch 0, 499/1036, loss:0.708816 \n","Epoch 0, 599/1036, loss:0.745519 \n","Epoch 0, 699/1036, loss:0.733979 \n","Epoch 0, 799/1036, loss:0.733330 \n","Epoch 0, 899/1036, loss:0.754551 \n","Epoch 0, 999/1036, loss:0.742039 \n","Epoch 0 cost time: 248.559s\n","Epoch Test 0, 49/1036\n","Epoch Test 0, 99/1036\n","Epoch Test 0, 149/1036\n","Epoch Test 0, 199/1036\n","Epoch Test 0, 249/1036\n","Epoch Test 0, 299/1036\n","Epoch Test 0, 349/1036\n","Epoch Test 0, 399/1036\n","Epoch Test 0, 449/1036\n","Epoch Test 0, 499/1036\n","Epoch Test 0, 549/1036\n","Epoch Test 0, 599/1036\n","Epoch Test 0, 649/1036\n","Epoch Test 0, 699/1036\n","Epoch Test 0, 749/1036\n","Epoch Test 0, 799/1036\n","Epoch Test 0, 849/1036\n","Epoch Test 0, 899/1036\n","Epoch Test 0, 949/1036\n","Epoch Test 0, 999/1036\n","Epoch Test 0 cost time: 25.622s\n","准确率： 0.776\n","Epoch 1, 99/1036, loss:0.735088 \n","Epoch 1, 199/1036, loss:0.713814 \n","Epoch 1, 299/1036, loss:0.754052 \n","Epoch 1, 399/1036, loss:0.743089 \n","Epoch 1, 499/1036, loss:0.737332 \n","Epoch 1, 599/1036, loss:0.735968 \n","Epoch 1, 699/1036, loss:0.744454 \n","Epoch 1, 799/1036, loss:0.727642 \n","Epoch 1, 899/1036, loss:0.747740 \n","Epoch 1, 999/1036, loss:0.725117 \n","Epoch 1 cost time: 248.566s\n","Epoch Test 1, 49/1036\n","Epoch Test 1, 99/1036\n","Epoch Test 1, 149/1036\n","Epoch Test 1, 199/1036\n","Epoch Test 1, 249/1036\n","Epoch Test 1, 299/1036\n","Epoch Test 1, 349/1036\n","Epoch Test 1, 399/1036\n","Epoch Test 1, 449/1036\n","Epoch Test 1, 499/1036\n","Epoch Test 1, 549/1036\n","Epoch Test 1, 599/1036\n","Epoch Test 1, 649/1036\n","Epoch Test 1, 699/1036\n","Epoch Test 1, 749/1036\n","Epoch Test 1, 799/1036\n","Epoch Test 1, 849/1036\n","Epoch Test 1, 899/1036\n","Epoch Test 1, 949/1036\n","Epoch Test 1, 999/1036\n","Epoch Test 1 cost time: 25.618s\n","准确率： 0.778\n","Epoch 2, 99/1036, loss:0.716322 \n","Epoch 2, 199/1036, loss:0.733781 \n","Epoch 2, 299/1036, loss:0.749142 \n","Epoch 2, 399/1036, loss:0.706103 \n","Epoch 2, 499/1036, loss:0.764947 \n","Epoch 2, 599/1036, loss:0.745325 \n","Epoch 2, 699/1036, loss:0.734227 \n","Epoch 2, 799/1036, loss:0.740622 \n","Epoch 2, 899/1036, loss:0.738736 \n","Epoch 2, 999/1036, loss:0.746088 \n","Epoch 2 cost time: 248.593s\n","Epoch Test 2, 49/1036\n","Epoch Test 2, 99/1036\n","Epoch Test 2, 149/1036\n","Epoch Test 2, 199/1036\n","Epoch Test 2, 249/1036\n","Epoch Test 2, 299/1036\n","Epoch Test 2, 349/1036\n","Epoch Test 2, 399/1036\n","Epoch Test 2, 449/1036\n","Epoch Test 2, 499/1036\n","Epoch Test 2, 549/1036\n","Epoch Test 2, 599/1036\n","Epoch Test 2, 649/1036\n","Epoch Test 2, 699/1036\n","Epoch Test 2, 749/1036\n","Epoch Test 2, 799/1036\n","Epoch Test 2, 849/1036\n","Epoch Test 2, 899/1036\n","Epoch Test 2, 949/1036\n","Epoch Test 2, 999/1036\n","Epoch Test 2 cost time: 25.637s\n","准确率： 0.779\n","Epoch 3, 99/1036, loss:0.748915 \n","Epoch 3, 199/1036, loss:0.727864 \n","Epoch 3, 299/1036, loss:0.695827 \n","Epoch 3, 399/1036, loss:0.741719 \n","Epoch 3, 499/1036, loss:0.725417 \n","Epoch 3, 599/1036, loss:0.754595 \n","Epoch 3, 699/1036, loss:0.719308 \n","Epoch 3, 799/1036, loss:0.702938 \n","Epoch 3, 899/1036, loss:0.716648 \n","Epoch 3, 999/1036, loss:0.719321 \n","Epoch 3 cost time: 248.577s\n","Epoch Test 3, 49/1036\n","Epoch Test 3, 99/1036\n","Epoch Test 3, 149/1036\n","Epoch Test 3, 199/1036\n","Epoch Test 3, 249/1036\n","Epoch Test 3, 299/1036\n","Epoch Test 3, 349/1036\n","Epoch Test 3, 399/1036\n","Epoch Test 3, 449/1036\n","Epoch Test 3, 499/1036\n","Epoch Test 3, 549/1036\n","Epoch Test 3, 599/1036\n","Epoch Test 3, 649/1036\n","Epoch Test 3, 699/1036\n","Epoch Test 3, 749/1036\n","Epoch Test 3, 799/1036\n","Epoch Test 3, 849/1036\n","Epoch Test 3, 899/1036\n","Epoch Test 3, 949/1036\n","Epoch Test 3, 999/1036\n","Epoch Test 3 cost time: 25.687s\n","准确率： 0.779\n","Epoch 4, 99/1036, loss:0.774846 \n","Epoch 4, 199/1036, loss:0.733468 \n","Epoch 4, 299/1036, loss:0.716956 \n","Epoch 4, 399/1036, loss:0.726730 \n","Epoch 4, 499/1036, loss:0.762676 \n","Epoch 4, 599/1036, loss:0.738979 \n","Epoch 4, 699/1036, loss:0.742952 \n","Epoch 4, 799/1036, loss:0.740749 \n","Epoch 4, 899/1036, loss:0.745155 \n","Epoch 4, 999/1036, loss:0.762746 \n","Epoch 4 cost time: 248.582s\n","Epoch Test 4, 49/1036\n","Epoch Test 4, 99/1036\n","Epoch Test 4, 149/1036\n","Epoch Test 4, 199/1036\n","Epoch Test 4, 249/1036\n","Epoch Test 4, 299/1036\n","Epoch Test 4, 349/1036\n","Epoch Test 4, 399/1036\n","Epoch Test 4, 449/1036\n","Epoch Test 4, 499/1036\n","Epoch Test 4, 549/1036\n","Epoch Test 4, 599/1036\n","Epoch Test 4, 649/1036\n","Epoch Test 4, 699/1036\n","Epoch Test 4, 749/1036\n","Epoch Test 4, 799/1036\n","Epoch Test 4, 849/1036\n","Epoch Test 4, 899/1036\n","Epoch Test 4, 949/1036\n","Epoch Test 4, 999/1036\n","Epoch Test 4 cost time: 25.779s\n","准确率： 0.780\n","Epoch 5, 99/1036, loss:0.733860 \n","Epoch 5, 199/1036, loss:0.708519 \n","Epoch 5, 299/1036, loss:0.731504 \n","Epoch 5, 399/1036, loss:0.746639 \n","Epoch 5, 499/1036, loss:0.691825 \n","Epoch 5, 599/1036, loss:0.726676 \n","Epoch 5, 699/1036, loss:0.752282 \n","Epoch 5, 799/1036, loss:0.749072 \n","Epoch 5, 899/1036, loss:0.735959 \n","Epoch 5, 999/1036, loss:0.744372 \n","Epoch 5 cost time: 248.594s\n","Epoch Test 5, 49/1036\n","Epoch Test 5, 99/1036\n","Epoch Test 5, 149/1036\n","Epoch Test 5, 199/1036\n","Epoch Test 5, 249/1036\n","Epoch Test 5, 299/1036\n","Epoch Test 5, 349/1036\n","Epoch Test 5, 399/1036\n","Epoch Test 5, 449/1036\n","Epoch Test 5, 499/1036\n","Epoch Test 5, 549/1036\n","Epoch Test 5, 599/1036\n","Epoch Test 5, 649/1036\n","Epoch Test 5, 699/1036\n","Epoch Test 5, 749/1036\n","Epoch Test 5, 799/1036\n","Epoch Test 5, 849/1036\n","Epoch Test 5, 899/1036\n","Epoch Test 5, 949/1036\n","Epoch Test 5, 999/1036\n","Epoch Test 5 cost time: 25.644s\n","准确率： 0.782\n","Epoch 6, 99/1036, loss:0.718459 \n","Epoch 6, 199/1036, loss:0.742215 \n","Epoch 6, 299/1036, loss:0.749446 \n","Epoch 6, 399/1036, loss:0.728776 \n","Epoch 6, 499/1036, loss:0.756907 \n","Epoch 6, 599/1036, loss:0.718499 \n","Epoch 6, 699/1036, loss:0.728890 \n","Epoch 6, 799/1036, loss:0.728800 \n","Epoch 6, 899/1036, loss:0.717327 \n","Epoch 6, 999/1036, loss:0.737426 \n","Epoch 6 cost time: 248.627s\n","Epoch Test 6, 49/1036\n","Epoch Test 6, 99/1036\n","Epoch Test 6, 149/1036\n","Epoch Test 6, 199/1036\n","Epoch Test 6, 249/1036\n","Epoch Test 6, 299/1036\n","Epoch Test 6, 349/1036\n","Epoch Test 6, 399/1036\n","Epoch Test 6, 449/1036\n","Epoch Test 6, 499/1036\n","Epoch Test 6, 549/1036\n","Epoch Test 6, 599/1036\n","Epoch Test 6, 649/1036\n","Epoch Test 6, 699/1036\n","Epoch Test 6, 749/1036\n","Epoch Test 6, 799/1036\n","Epoch Test 6, 849/1036\n","Epoch Test 6, 899/1036\n","Epoch Test 6, 949/1036\n","Epoch Test 6, 999/1036\n","Epoch Test 6 cost time: 25.625s\n","准确率： 0.782\n","Epoch 7, 99/1036, loss:0.731323 \n","Epoch 7, 199/1036, loss:0.710090 \n","Epoch 7, 299/1036, loss:0.725082 \n","Epoch 7, 399/1036, loss:0.710099 \n","Epoch 7, 499/1036, loss:0.720119 \n","Epoch 7, 599/1036, loss:0.713959 \n","Epoch 7, 699/1036, loss:0.734755 \n","Epoch 7, 799/1036, loss:0.714987 \n","Epoch 7, 899/1036, loss:0.715451 \n","Epoch 7, 999/1036, loss:0.750591 \n","Epoch 7 cost time: 248.885s\n","Epoch Test 7, 49/1036\n","Epoch Test 7, 99/1036\n","Epoch Test 7, 149/1036\n","Epoch Test 7, 199/1036\n","Epoch Test 7, 249/1036\n","Epoch Test 7, 299/1036\n","Epoch Test 7, 349/1036\n","Epoch Test 7, 399/1036\n","Epoch Test 7, 449/1036\n","Epoch Test 7, 499/1036\n","Epoch Test 7, 549/1036\n","Epoch Test 7, 599/1036\n","Epoch Test 7, 649/1036\n","Epoch Test 7, 699/1036\n","Epoch Test 7, 749/1036\n","Epoch Test 7, 799/1036\n","Epoch Test 7, 849/1036\n","Epoch Test 7, 899/1036\n","Epoch Test 7, 949/1036\n","Epoch Test 7, 999/1036\n","Epoch Test 7 cost time: 25.648s\n","准确率： 0.783\n","Epoch 8, 99/1036, loss:0.729966 \n","Epoch 8, 199/1036, loss:0.688317 \n","Epoch 8, 299/1036, loss:0.706118 \n","Epoch 8, 399/1036, loss:0.717201 \n","Epoch 8, 499/1036, loss:0.734895 \n","Epoch 8, 599/1036, loss:0.725245 \n","Epoch 8, 699/1036, loss:0.727784 \n","Epoch 8, 799/1036, loss:0.741322 \n","Epoch 8, 899/1036, loss:0.757149 \n","Epoch 8, 999/1036, loss:0.724104 \n","Epoch 8 cost time: 248.787s\n","Epoch Test 8, 49/1036\n","Epoch Test 8, 99/1036\n","Epoch Test 8, 149/1036\n","Epoch Test 8, 199/1036\n","Epoch Test 8, 249/1036\n","Epoch Test 8, 299/1036\n","Epoch Test 8, 349/1036\n","Epoch Test 8, 399/1036\n","Epoch Test 8, 449/1036\n","Epoch Test 8, 499/1036\n","Epoch Test 8, 549/1036\n","Epoch Test 8, 599/1036\n","Epoch Test 8, 649/1036\n","Epoch Test 8, 699/1036\n","Epoch Test 8, 749/1036\n","Epoch Test 8, 799/1036\n","Epoch Test 8, 849/1036\n","Epoch Test 8, 899/1036\n","Epoch Test 8, 949/1036\n","Epoch Test 8, 999/1036\n","Epoch Test 8 cost time: 25.630s\n","准确率： 0.784\n","Epoch 9, 99/1036, loss:0.744570 \n","Epoch 9, 199/1036, loss:0.771958 \n","Epoch 9, 299/1036, loss:0.727145 \n","Epoch 9, 399/1036, loss:0.710532 \n","Epoch 9, 499/1036, loss:0.707352 \n","Epoch 9, 599/1036, loss:0.752852 \n","Epoch 9, 699/1036, loss:0.729992 \n","Epoch 9, 799/1036, loss:0.724661 \n","Epoch 9, 899/1036, loss:0.741282 \n","Epoch 9, 999/1036, loss:0.765389 \n","Epoch 9 cost time: 248.640s\n","Epoch Test 9, 49/1036\n","Epoch Test 9, 99/1036\n","Epoch Test 9, 149/1036\n","Epoch Test 9, 199/1036\n","Epoch Test 9, 249/1036\n","Epoch Test 9, 299/1036\n","Epoch Test 9, 349/1036\n","Epoch Test 9, 399/1036\n","Epoch Test 9, 449/1036\n","Epoch Test 9, 499/1036\n","Epoch Test 9, 549/1036\n","Epoch Test 9, 599/1036\n","Epoch Test 9, 649/1036\n","Epoch Test 9, 699/1036\n","Epoch Test 9, 749/1036\n","Epoch Test 9, 799/1036\n","Epoch Test 9, 849/1036\n","Epoch Test 9, 899/1036\n","Epoch Test 9, 949/1036\n","Epoch Test 9, 999/1036\n","Epoch Test 9 cost time: 25.625s\n","准确率： 0.785\n","Epoch 10, 99/1036, loss:0.710195 \n","Epoch 10, 199/1036, loss:0.729105 \n","Epoch 10, 299/1036, loss:0.709619 \n","Epoch 10, 399/1036, loss:0.715233 \n","Epoch 10, 499/1036, loss:0.720087 \n","Epoch 10, 599/1036, loss:0.741550 \n","Epoch 10, 699/1036, loss:0.730280 \n","Epoch 10, 799/1036, loss:0.720911 \n","Epoch 10, 899/1036, loss:0.736267 \n","Epoch 10, 999/1036, loss:0.727431 \n","Epoch 10 cost time: 248.564s\n","Epoch Test 10, 49/1036\n","Epoch Test 10, 99/1036\n","Epoch Test 10, 149/1036\n","Epoch Test 10, 199/1036\n","Epoch Test 10, 249/1036\n","Epoch Test 10, 299/1036\n","Epoch Test 10, 349/1036\n","Epoch Test 10, 399/1036\n","Epoch Test 10, 449/1036\n","Epoch Test 10, 499/1036\n","Epoch Test 10, 549/1036\n","Epoch Test 10, 599/1036\n","Epoch Test 10, 649/1036\n","Epoch Test 10, 699/1036\n","Epoch Test 10, 749/1036\n","Epoch Test 10, 799/1036\n","Epoch Test 10, 849/1036\n","Epoch Test 10, 899/1036\n","Epoch Test 10, 949/1036\n","Epoch Test 10, 999/1036\n","Epoch Test 10 cost time: 25.640s\n","准确率： 0.784\n","Epoch 11, 99/1036, loss:0.722911 \n","Epoch 11, 199/1036, loss:0.765426 \n","Epoch 11, 299/1036, loss:0.726345 \n","Epoch 11, 399/1036, loss:0.762677 \n","Epoch 11, 499/1036, loss:0.717685 \n","Epoch 11, 599/1036, loss:0.696342 \n","Epoch 11, 699/1036, loss:0.724289 \n","Epoch 11, 799/1036, loss:0.743022 \n","Epoch 11, 899/1036, loss:0.723942 \n","Epoch 11, 999/1036, loss:0.756875 \n","Epoch 11 cost time: 248.573s\n","Epoch Test 11, 49/1036\n","Epoch Test 11, 99/1036\n","Epoch Test 11, 149/1036\n","Epoch Test 11, 199/1036\n","Epoch Test 11, 249/1036\n","Epoch Test 11, 299/1036\n","Epoch Test 11, 349/1036\n","Epoch Test 11, 399/1036\n","Epoch Test 11, 449/1036\n","Epoch Test 11, 499/1036\n","Epoch Test 11, 549/1036\n","Epoch Test 11, 599/1036\n","Epoch Test 11, 649/1036\n","Epoch Test 11, 699/1036\n","Epoch Test 11, 749/1036\n","Epoch Test 11, 799/1036\n","Epoch Test 11, 849/1036\n","Epoch Test 11, 899/1036\n","Epoch Test 11, 949/1036\n","Epoch Test 11, 999/1036\n","Epoch Test 11 cost time: 25.626s\n","准确率： 0.786\n","Epoch 12, 99/1036, loss:0.699917 \n","Epoch 12, 199/1036, loss:0.729836 \n","Epoch 12, 299/1036, loss:0.741790 \n","Epoch 12, 399/1036, loss:0.723588 \n","Epoch 12, 499/1036, loss:0.711981 \n","Epoch 12, 599/1036, loss:0.734494 \n","Epoch 12, 699/1036, loss:0.724395 \n","Epoch 12, 799/1036, loss:0.729918 \n","Epoch 12, 899/1036, loss:0.728440 \n","Epoch 12, 999/1036, loss:0.715699 \n","Epoch 12 cost time: 248.641s\n","Epoch Test 12, 49/1036\n","Epoch Test 12, 99/1036\n","Epoch Test 12, 149/1036\n","Epoch Test 12, 199/1036\n","Epoch Test 12, 249/1036\n","Epoch Test 12, 299/1036\n","Epoch Test 12, 349/1036\n","Epoch Test 12, 399/1036\n","Epoch Test 12, 449/1036\n","Epoch Test 12, 499/1036\n","Epoch Test 12, 549/1036\n","Epoch Test 12, 599/1036\n","Epoch Test 12, 649/1036\n","Epoch Test 12, 699/1036\n","Epoch Test 12, 749/1036\n","Epoch Test 12, 799/1036\n","Epoch Test 12, 849/1036\n","Epoch Test 12, 899/1036\n","Epoch Test 12, 949/1036\n","Epoch Test 12, 999/1036\n","Epoch Test 12 cost time: 25.645s\n","准确率： 0.787\n","Epoch 13, 99/1036, loss:0.727252 \n","Epoch 13, 199/1036, loss:0.726905 \n","Epoch 13, 299/1036, loss:0.724298 \n","Epoch 13, 399/1036, loss:0.724601 \n","Epoch 13, 499/1036, loss:0.685292 \n","Epoch 13, 599/1036, loss:0.735856 \n","Epoch 13, 699/1036, loss:0.726014 \n","Epoch 13, 799/1036, loss:0.728684 \n","Epoch 13, 899/1036, loss:0.751829 \n","Epoch 13, 999/1036, loss:0.719381 \n","Epoch 13 cost time: 248.579s\n","Epoch Test 13, 49/1036\n","Epoch Test 13, 99/1036\n","Epoch Test 13, 149/1036\n","Epoch Test 13, 199/1036\n","Epoch Test 13, 249/1036\n","Epoch Test 13, 299/1036\n","Epoch Test 13, 349/1036\n","Epoch Test 13, 399/1036\n","Epoch Test 13, 449/1036\n","Epoch Test 13, 499/1036\n","Epoch Test 13, 549/1036\n","Epoch Test 13, 599/1036\n","Epoch Test 13, 649/1036\n","Epoch Test 13, 699/1036\n","Epoch Test 13, 749/1036\n","Epoch Test 13, 799/1036\n","Epoch Test 13, 849/1036\n","Epoch Test 13, 899/1036\n","Epoch Test 13, 949/1036\n","Epoch Test 13, 999/1036\n","Epoch Test 13 cost time: 25.649s\n","准确率： 0.786\n","Epoch 14, 99/1036, loss:0.702839 \n","Epoch 14, 199/1036, loss:0.725965 \n","Epoch 14, 299/1036, loss:0.745709 \n","Epoch 14, 399/1036, loss:0.707624 \n","Epoch 14, 499/1036, loss:0.721820 \n","Epoch 14, 599/1036, loss:0.717601 \n","Epoch 14, 699/1036, loss:0.759998 \n","Epoch 14, 799/1036, loss:0.720183 \n","Epoch 14, 899/1036, loss:0.725936 \n","Epoch 14, 999/1036, loss:0.711518 \n","Epoch 14 cost time: 248.884s\n","Epoch Test 14, 49/1036\n","Epoch Test 14, 99/1036\n","Epoch Test 14, 149/1036\n","Epoch Test 14, 199/1036\n","Epoch Test 14, 249/1036\n","Epoch Test 14, 299/1036\n","Epoch Test 14, 349/1036\n","Epoch Test 14, 399/1036\n","Epoch Test 14, 449/1036\n","Epoch Test 14, 499/1036\n","Epoch Test 14, 549/1036\n","Epoch Test 14, 599/1036\n","Epoch Test 14, 649/1036\n","Epoch Test 14, 699/1036\n","Epoch Test 14, 749/1036\n","Epoch Test 14, 799/1036\n","Epoch Test 14, 849/1036\n","Epoch Test 14, 899/1036\n","Epoch Test 14, 949/1036\n","Epoch Test 14, 999/1036\n","Epoch Test 14 cost time: 25.631s\n","准确率： 0.789\n","Epoch 15, 99/1036, loss:0.725365 \n","Epoch 15, 199/1036, loss:0.719856 \n","Epoch 15, 299/1036, loss:0.736236 \n","Epoch 15, 399/1036, loss:0.742788 \n","Epoch 15, 499/1036, loss:0.710037 \n","Epoch 15, 599/1036, loss:0.719504 \n","Epoch 15, 699/1036, loss:0.723975 \n","Epoch 15, 799/1036, loss:0.710394 \n","Epoch 15, 899/1036, loss:0.740672 \n","Epoch 15, 999/1036, loss:0.720755 \n","Epoch 15 cost time: 248.592s\n","Epoch Test 15, 49/1036\n","Epoch Test 15, 99/1036\n","Epoch Test 15, 149/1036\n","Epoch Test 15, 199/1036\n","Epoch Test 15, 249/1036\n","Epoch Test 15, 299/1036\n","Epoch Test 15, 349/1036\n","Epoch Test 15, 399/1036\n","Epoch Test 15, 449/1036\n","Epoch Test 15, 499/1036\n","Epoch Test 15, 549/1036\n","Epoch Test 15, 599/1036\n","Epoch Test 15, 649/1036\n","Epoch Test 15, 699/1036\n","Epoch Test 15, 749/1036\n","Epoch Test 15, 799/1036\n","Epoch Test 15, 849/1036\n","Epoch Test 15, 899/1036\n","Epoch Test 15, 949/1036\n","Epoch Test 15, 999/1036\n","Epoch Test 15 cost time: 25.636s\n","准确率： 0.789\n","Epoch 16, 99/1036, loss:0.715732 \n","Epoch 16, 199/1036, loss:0.755186 \n","Epoch 16, 299/1036, loss:0.727755 \n","Epoch 16, 399/1036, loss:0.736136 \n","Epoch 16, 499/1036, loss:0.708388 \n","Epoch 16, 599/1036, loss:0.719783 \n","Epoch 16, 699/1036, loss:0.738617 \n","Epoch 16, 799/1036, loss:0.727842 \n","Epoch 16, 899/1036, loss:0.740922 \n","Epoch 16, 999/1036, loss:0.714821 \n","Epoch 16 cost time: 248.582s\n","Epoch Test 16, 49/1036\n","Epoch Test 16, 99/1036\n","Epoch Test 16, 149/1036\n","Epoch Test 16, 199/1036\n","Epoch Test 16, 249/1036\n","Epoch Test 16, 299/1036\n","Epoch Test 16, 349/1036\n","Epoch Test 16, 399/1036\n","Epoch Test 16, 449/1036\n","Epoch Test 16, 499/1036\n","Epoch Test 16, 549/1036\n","Epoch Test 16, 599/1036\n","Epoch Test 16, 649/1036\n","Epoch Test 16, 699/1036\n","Epoch Test 16, 749/1036\n","Epoch Test 16, 799/1036\n","Epoch Test 16, 849/1036\n","Epoch Test 16, 899/1036\n","Epoch Test 16, 949/1036\n","Epoch Test 16, 999/1036\n","Epoch Test 16 cost time: 25.634s\n","准确率： 0.789\n","Epoch 17, 99/1036, loss:0.700161 \n","Epoch 17, 199/1036, loss:0.727870 \n","Epoch 17, 299/1036, loss:0.734994 \n","Epoch 17, 399/1036, loss:0.715164 \n","Epoch 17, 499/1036, loss:0.743797 \n","Epoch 17, 599/1036, loss:0.700517 \n","Epoch 17, 699/1036, loss:0.717339 \n","Epoch 17, 799/1036, loss:0.729427 \n","Epoch 17, 899/1036, loss:0.690327 \n","Epoch 17, 999/1036, loss:0.739555 \n","Epoch 17 cost time: 248.575s\n","Epoch Test 17, 49/1036\n","Epoch Test 17, 99/1036\n","Epoch Test 17, 149/1036\n","Epoch Test 17, 199/1036\n","Epoch Test 17, 249/1036\n","Epoch Test 17, 299/1036\n","Epoch Test 17, 349/1036\n","Epoch Test 17, 399/1036\n","Epoch Test 17, 449/1036\n","Epoch Test 17, 499/1036\n","Epoch Test 17, 549/1036\n","Epoch Test 17, 599/1036\n","Epoch Test 17, 649/1036\n","Epoch Test 17, 699/1036\n","Epoch Test 17, 749/1036\n","Epoch Test 17, 799/1036\n","Epoch Test 17, 849/1036\n","Epoch Test 17, 899/1036\n","Epoch Test 17, 949/1036\n","Epoch Test 17, 999/1036\n","Epoch Test 17 cost time: 25.764s\n","准确率： 0.790\n","Epoch 18, 99/1036, loss:0.725630 \n","Epoch 18, 199/1036, loss:0.715727 \n","Epoch 18, 299/1036, loss:0.722567 \n","Epoch 18, 399/1036, loss:0.723332 \n","Epoch 18, 499/1036, loss:0.727235 \n","Epoch 18, 599/1036, loss:0.745992 \n","Epoch 18, 699/1036, loss:0.718020 \n","Epoch 18, 799/1036, loss:0.711667 \n","Epoch 18, 899/1036, loss:0.713398 \n","Epoch 18, 999/1036, loss:0.692638 \n","Epoch 18 cost time: 248.763s\n","Epoch Test 18, 49/1036\n","Epoch Test 18, 99/1036\n","Epoch Test 18, 149/1036\n","Epoch Test 18, 199/1036\n","Epoch Test 18, 249/1036\n","Epoch Test 18, 299/1036\n","Epoch Test 18, 349/1036\n","Epoch Test 18, 399/1036\n","Epoch Test 18, 449/1036\n","Epoch Test 18, 499/1036\n","Epoch Test 18, 549/1036\n","Epoch Test 18, 599/1036\n","Epoch Test 18, 649/1036\n","Epoch Test 18, 699/1036\n","Epoch Test 18, 749/1036\n","Epoch Test 18, 799/1036\n","Epoch Test 18, 849/1036\n","Epoch Test 18, 899/1036\n","Epoch Test 18, 949/1036\n","Epoch Test 18, 999/1036\n","Epoch Test 18 cost time: 25.654s\n","准确率： 0.790\n","Epoch 19, 99/1036, loss:0.684014 \n","Epoch 19, 199/1036, loss:0.727054 \n","Epoch 19, 299/1036, loss:0.739216 \n","Epoch 19, 399/1036, loss:0.705498 \n","Epoch 19, 499/1036, loss:0.703194 \n","Epoch 19, 599/1036, loss:0.705615 \n","Epoch 19, 699/1036, loss:0.740738 \n","Epoch 19, 799/1036, loss:0.732477 \n","Epoch 19, 899/1036, loss:0.698395 \n","Epoch 19, 999/1036, loss:0.719376 \n","Epoch 19 cost time: 248.622s\n","Epoch Test 19, 49/1036\n","Epoch Test 19, 99/1036\n","Epoch Test 19, 149/1036\n","Epoch Test 19, 199/1036\n","Epoch Test 19, 249/1036\n","Epoch Test 19, 299/1036\n","Epoch Test 19, 349/1036\n","Epoch Test 19, 399/1036\n","Epoch Test 19, 449/1036\n","Epoch Test 19, 499/1036\n","Epoch Test 19, 549/1036\n","Epoch Test 19, 599/1036\n","Epoch Test 19, 649/1036\n","Epoch Test 19, 699/1036\n","Epoch Test 19, 749/1036\n","Epoch Test 19, 799/1036\n","Epoch Test 19, 849/1036\n","Epoch Test 19, 899/1036\n","Epoch Test 19, 949/1036\n","Epoch Test 19, 999/1036\n","Epoch Test 19 cost time: 25.634s\n","准确率： 0.790\n","Epoch Test 20, 49/1036\n","Epoch Test 20, 99/1036\n","Epoch Test 20, 149/1036\n","Epoch Test 20, 199/1036\n","Epoch Test 20, 249/1036\n","Epoch Test 20, 299/1036\n","Epoch Test 20, 349/1036\n","Epoch Test 20, 399/1036\n","Epoch Test 20, 449/1036\n","Epoch Test 20, 499/1036\n","Epoch Test 20, 549/1036\n","Epoch Test 20, 599/1036\n","Epoch Test 20, 649/1036\n","Epoch Test 20, 699/1036\n","Epoch Test 20, 749/1036\n","Epoch Test 20, 799/1036\n","Epoch Test 20, 849/1036\n","Epoch Test 20, 899/1036\n","Epoch Test 20, 949/1036\n","Epoch Test 20, 999/1036\n","Epoch Test 20 cost time: 26.034s\n","准确率： 0.790\n","Epoch 0, 99/1036, loss:0.725863 \n","Epoch 0, 199/1036, loss:0.735406 \n","Epoch 0, 299/1036, loss:0.721901 \n","Epoch 0, 399/1036, loss:0.706939 \n","Epoch 0, 499/1036, loss:0.712268 \n","Epoch 0, 599/1036, loss:0.717319 \n","Epoch 0, 699/1036, loss:0.717576 \n","Epoch 0, 799/1036, loss:0.706421 \n","Epoch 0, 899/1036, loss:0.762483 \n","Epoch 0, 999/1036, loss:0.720488 \n","Epoch 0 cost time: 248.786s\n","Epoch Test 0, 49/1036\n","Epoch Test 0, 99/1036\n","Epoch Test 0, 149/1036\n","Epoch Test 0, 199/1036\n","Epoch Test 0, 249/1036\n","Epoch Test 0, 299/1036\n","Epoch Test 0, 349/1036\n","Epoch Test 0, 399/1036\n","Epoch Test 0, 449/1036\n","Epoch Test 0, 499/1036\n","Epoch Test 0, 549/1036\n","Epoch Test 0, 599/1036\n","Epoch Test 0, 649/1036\n","Epoch Test 0, 699/1036\n","Epoch Test 0, 749/1036\n","Epoch Test 0, 799/1036\n","Epoch Test 0, 849/1036\n","Epoch Test 0, 899/1036\n","Epoch Test 0, 949/1036\n","Epoch Test 0, 999/1036\n","Epoch Test 0 cost time: 25.627s\n","准确率： 0.792\n","Epoch 1, 99/1036, loss:0.705610 \n","Epoch 1, 199/1036, loss:0.707707 \n","Epoch 1, 299/1036, loss:0.706722 \n","Epoch 1, 399/1036, loss:0.710705 \n","Epoch 1, 499/1036, loss:0.740776 \n","Epoch 1, 599/1036, loss:0.720777 \n","Epoch 1, 699/1036, loss:0.704415 \n","Epoch 1, 799/1036, loss:0.713845 \n","Epoch 1, 899/1036, loss:0.721798 \n","Epoch 1, 999/1036, loss:0.702553 \n","Epoch 1 cost time: 248.606s\n","Epoch Test 1, 49/1036\n","Epoch Test 1, 99/1036\n","Epoch Test 1, 149/1036\n","Epoch Test 1, 199/1036\n","Epoch Test 1, 249/1036\n","Epoch Test 1, 299/1036\n","Epoch Test 1, 349/1036\n","Epoch Test 1, 399/1036\n","Epoch Test 1, 449/1036\n","Epoch Test 1, 499/1036\n","Epoch Test 1, 549/1036\n","Epoch Test 1, 599/1036\n","Epoch Test 1, 649/1036\n","Epoch Test 1, 699/1036\n","Epoch Test 1, 749/1036\n","Epoch Test 1, 799/1036\n","Epoch Test 1, 849/1036\n","Epoch Test 1, 899/1036\n","Epoch Test 1, 949/1036\n","Epoch Test 1, 999/1036\n","Epoch Test 1 cost time: 25.644s\n","准确率： 0.793\n","Epoch 2, 99/1036, loss:0.716267 \n","Epoch 2, 199/1036, loss:0.711525 \n","Epoch 2, 299/1036, loss:0.720633 \n","Epoch 2, 399/1036, loss:0.707789 \n","Epoch 2, 499/1036, loss:0.696654 \n","Epoch 2, 599/1036, loss:0.682956 \n","Epoch 2, 699/1036, loss:0.704034 \n","Epoch 2, 799/1036, loss:0.737884 \n","Epoch 2, 899/1036, loss:0.730817 \n","Epoch 2, 999/1036, loss:0.714859 \n","Epoch 2 cost time: 248.749s\n","Epoch Test 2, 49/1036\n","Epoch Test 2, 99/1036\n","Epoch Test 2, 149/1036\n","Epoch Test 2, 199/1036\n","Epoch Test 2, 249/1036\n","Epoch Test 2, 299/1036\n","Epoch Test 2, 349/1036\n","Epoch Test 2, 399/1036\n","Epoch Test 2, 449/1036\n","Epoch Test 2, 499/1036\n","Epoch Test 2, 549/1036\n","Epoch Test 2, 599/1036\n","Epoch Test 2, 649/1036\n","Epoch Test 2, 699/1036\n","Epoch Test 2, 749/1036\n","Epoch Test 2, 799/1036\n","Epoch Test 2, 849/1036\n","Epoch Test 2, 899/1036\n","Epoch Test 2, 949/1036\n","Epoch Test 2, 999/1036\n","Epoch Test 2 cost time: 25.645s\n","准确率： 0.793\n","Epoch 3, 99/1036, loss:0.710330 \n","Epoch 3, 199/1036, loss:0.726919 \n","Epoch 3, 299/1036, loss:0.696426 \n","Epoch 3, 399/1036, loss:0.704656 \n","Epoch 3, 499/1036, loss:0.720135 \n","Epoch 3, 599/1036, loss:0.676153 \n","Epoch 3, 699/1036, loss:0.691518 \n","Epoch 3, 799/1036, loss:0.742661 \n","Epoch 3, 899/1036, loss:0.704873 \n","Epoch 3, 999/1036, loss:0.698380 \n","Epoch 3 cost time: 248.619s\n","Epoch Test 3, 49/1036\n","Epoch Test 3, 99/1036\n","Epoch Test 3, 149/1036\n","Epoch Test 3, 199/1036\n","Epoch Test 3, 249/1036\n","Epoch Test 3, 299/1036\n","Epoch Test 3, 349/1036\n","Epoch Test 3, 399/1036\n","Epoch Test 3, 449/1036\n","Epoch Test 3, 499/1036\n","Epoch Test 3, 549/1036\n","Epoch Test 3, 599/1036\n","Epoch Test 3, 649/1036\n","Epoch Test 3, 699/1036\n","Epoch Test 3, 749/1036\n","Epoch Test 3, 799/1036\n","Epoch Test 3, 849/1036\n","Epoch Test 3, 899/1036\n","Epoch Test 3, 949/1036\n","Epoch Test 3, 999/1036\n","Epoch Test 3 cost time: 25.650s\n","准确率： 0.792\n","Epoch 4, 99/1036, loss:0.735724 \n","Epoch 4, 199/1036, loss:0.692447 \n","Epoch 4, 299/1036, loss:0.701268 \n","Epoch 4, 399/1036, loss:0.716675 \n","Epoch 4, 499/1036, loss:0.699730 \n","Epoch 4, 599/1036, loss:0.719372 \n","Epoch 4, 699/1036, loss:0.718784 \n","Epoch 4, 799/1036, loss:0.708649 \n","Epoch 4, 899/1036, loss:0.718314 \n","Epoch 4, 999/1036, loss:0.702451 \n","Epoch 4 cost time: 248.573s\n","Epoch Test 4, 49/1036\n","Epoch Test 4, 99/1036\n","Epoch Test 4, 149/1036\n","Epoch Test 4, 199/1036\n","Epoch Test 4, 249/1036\n","Epoch Test 4, 299/1036\n","Epoch Test 4, 349/1036\n","Epoch Test 4, 399/1036\n","Epoch Test 4, 449/1036\n","Epoch Test 4, 499/1036\n","Epoch Test 4, 549/1036\n","Epoch Test 4, 599/1036\n","Epoch Test 4, 649/1036\n","Epoch Test 4, 699/1036\n","Epoch Test 4, 749/1036\n","Epoch Test 4, 799/1036\n","Epoch Test 4, 849/1036\n","Epoch Test 4, 899/1036\n","Epoch Test 4, 949/1036\n","Epoch Test 4, 999/1036\n","Epoch Test 4 cost time: 25.643s\n","准确率： 0.791\n","Epoch 5, 99/1036, loss:0.704657 \n","Epoch 5, 199/1036, loss:0.714087 \n","Epoch 5, 299/1036, loss:0.716893 \n","Epoch 5, 399/1036, loss:0.725768 \n","Epoch 5, 499/1036, loss:0.737987 \n","Epoch 5, 599/1036, loss:0.691247 \n","Epoch 5, 699/1036, loss:0.701551 \n","Epoch 5, 799/1036, loss:0.738544 \n","Epoch 5, 899/1036, loss:0.732315 \n","Epoch 5, 999/1036, loss:0.699654 \n","Epoch 5 cost time: 248.538s\n","Epoch Test 5, 49/1036\n","Epoch Test 5, 99/1036\n","Epoch Test 5, 149/1036\n","Epoch Test 5, 199/1036\n","Epoch Test 5, 249/1036\n","Epoch Test 5, 299/1036\n","Epoch Test 5, 349/1036\n","Epoch Test 5, 399/1036\n","Epoch Test 5, 449/1036\n","Epoch Test 5, 499/1036\n","Epoch Test 5, 549/1036\n","Epoch Test 5, 599/1036\n","Epoch Test 5, 649/1036\n","Epoch Test 5, 699/1036\n","Epoch Test 5, 749/1036\n","Epoch Test 5, 799/1036\n","Epoch Test 5, 849/1036\n","Epoch Test 5, 899/1036\n","Epoch Test 5, 949/1036\n","Epoch Test 5, 999/1036\n","Epoch Test 5 cost time: 25.681s\n","准确率： 0.794\n","Epoch 6, 99/1036, loss:0.699072 \n","Epoch 6, 199/1036, loss:0.730183 \n","Epoch 6, 299/1036, loss:0.722502 \n","Epoch 6, 399/1036, loss:0.733990 \n","Epoch 6, 499/1036, loss:0.742519 \n","Epoch 6, 599/1036, loss:0.706611 \n","Epoch 6, 699/1036, loss:0.692170 \n","Epoch 6, 799/1036, loss:0.711003 \n","Epoch 6, 899/1036, loss:0.700587 \n","Epoch 6, 999/1036, loss:0.695569 \n","Epoch 6 cost time: 248.701s\n","Epoch Test 6, 49/1036\n","Epoch Test 6, 99/1036\n","Epoch Test 6, 149/1036\n","Epoch Test 6, 199/1036\n","Epoch Test 6, 249/1036\n","Epoch Test 6, 299/1036\n","Epoch Test 6, 349/1036\n","Epoch Test 6, 399/1036\n","Epoch Test 6, 449/1036\n","Epoch Test 6, 499/1036\n","Epoch Test 6, 549/1036\n","Epoch Test 6, 599/1036\n","Epoch Test 6, 649/1036\n","Epoch Test 6, 699/1036\n","Epoch Test 6, 749/1036\n","Epoch Test 6, 799/1036\n","Epoch Test 6, 849/1036\n","Epoch Test 6, 899/1036\n","Epoch Test 6, 949/1036\n","Epoch Test 6, 999/1036\n","Epoch Test 6 cost time: 25.620s\n","准确率： 0.794\n","Epoch 7, 99/1036, loss:0.739837 \n","Epoch 7, 199/1036, loss:0.725295 \n","Epoch 7, 299/1036, loss:0.713043 \n","Epoch 7, 399/1036, loss:0.704498 \n","Epoch 7, 499/1036, loss:0.691679 \n","Epoch 7, 599/1036, loss:0.695039 \n","Epoch 7, 699/1036, loss:0.728969 \n","Epoch 7, 799/1036, loss:0.708184 \n","Epoch 7, 899/1036, loss:0.710731 \n","Epoch 7, 999/1036, loss:0.693448 \n","Epoch 7 cost time: 248.614s\n","Epoch Test 7, 49/1036\n","Epoch Test 7, 99/1036\n","Epoch Test 7, 149/1036\n","Epoch Test 7, 199/1036\n","Epoch Test 7, 249/1036\n","Epoch Test 7, 299/1036\n","Epoch Test 7, 349/1036\n","Epoch Test 7, 399/1036\n","Epoch Test 7, 449/1036\n","Epoch Test 7, 499/1036\n","Epoch Test 7, 549/1036\n","Epoch Test 7, 599/1036\n","Epoch Test 7, 649/1036\n","Epoch Test 7, 699/1036\n","Epoch Test 7, 749/1036\n","Epoch Test 7, 799/1036\n","Epoch Test 7, 849/1036\n","Epoch Test 7, 899/1036\n","Epoch Test 7, 949/1036\n","Epoch Test 7, 999/1036\n","Epoch Test 7 cost time: 25.647s\n","准确率： 0.794\n","Epoch 8, 99/1036, loss:0.718541 \n","Epoch 8, 199/1036, loss:0.715417 \n","Epoch 8, 299/1036, loss:0.718974 \n","Epoch 8, 399/1036, loss:0.721580 \n","Epoch 8, 499/1036, loss:0.720522 \n","Epoch 8, 599/1036, loss:0.710671 \n","Epoch 8, 699/1036, loss:0.711903 \n","Epoch 8, 799/1036, loss:0.690519 \n","Epoch 8, 899/1036, loss:0.709845 \n","Epoch 8, 999/1036, loss:0.714649 \n","Epoch 8 cost time: 248.948s\n","Epoch Test 8, 49/1036\n","Epoch Test 8, 99/1036\n","Epoch Test 8, 149/1036\n","Epoch Test 8, 199/1036\n","Epoch Test 8, 249/1036\n","Epoch Test 8, 299/1036\n","Epoch Test 8, 349/1036\n","Epoch Test 8, 399/1036\n","Epoch Test 8, 449/1036\n","Epoch Test 8, 499/1036\n","Epoch Test 8, 549/1036\n","Epoch Test 8, 599/1036\n","Epoch Test 8, 649/1036\n","Epoch Test 8, 699/1036\n","Epoch Test 8, 749/1036\n","Epoch Test 8, 799/1036\n","Epoch Test 8, 849/1036\n","Epoch Test 8, 899/1036\n","Epoch Test 8, 949/1036\n","Epoch Test 8, 999/1036\n","Epoch Test 8 cost time: 25.631s\n","准确率： 0.795\n","Epoch 9, 99/1036, loss:0.717067 \n","Epoch 9, 199/1036, loss:0.716464 \n","Epoch 9, 299/1036, loss:0.718346 \n","Epoch 9, 399/1036, loss:0.718453 \n","Epoch 9, 499/1036, loss:0.692187 \n","Epoch 9, 599/1036, loss:0.715712 \n","Epoch 9, 699/1036, loss:0.679551 \n","Epoch 9, 799/1036, loss:0.705182 \n","Epoch 9, 899/1036, loss:0.696812 \n","Epoch 9, 999/1036, loss:0.710429 \n","Epoch 9 cost time: 248.636s\n","Epoch Test 9, 49/1036\n","Epoch Test 9, 99/1036\n","Epoch Test 9, 149/1036\n","Epoch Test 9, 199/1036\n","Epoch Test 9, 249/1036\n","Epoch Test 9, 299/1036\n","Epoch Test 9, 349/1036\n","Epoch Test 9, 399/1036\n","Epoch Test 9, 449/1036\n","Epoch Test 9, 499/1036\n","Epoch Test 9, 549/1036\n","Epoch Test 9, 599/1036\n","Epoch Test 9, 649/1036\n","Epoch Test 9, 699/1036\n","Epoch Test 9, 749/1036\n","Epoch Test 9, 799/1036\n","Epoch Test 9, 849/1036\n","Epoch Test 9, 899/1036\n","Epoch Test 9, 949/1036\n","Epoch Test 9, 999/1036\n","Epoch Test 9 cost time: 25.666s\n","准确率： 0.795\n","Epoch 10, 99/1036, loss:0.724772 \n","Epoch 10, 199/1036, loss:0.700590 \n","Epoch 10, 299/1036, loss:0.711376 \n","Epoch 10, 399/1036, loss:0.706245 \n","Epoch 10, 499/1036, loss:0.682422 \n","Epoch 10, 599/1036, loss:0.700356 \n","Epoch 10, 699/1036, loss:0.700358 \n","Epoch 10, 799/1036, loss:0.690398 \n","Epoch 10, 899/1036, loss:0.702914 \n","Epoch 10, 999/1036, loss:0.710550 \n","Epoch 10 cost time: 248.559s\n","Epoch Test 10, 49/1036\n","Epoch Test 10, 99/1036\n","Epoch Test 10, 149/1036\n","Epoch Test 10, 199/1036\n","Epoch Test 10, 249/1036\n","Epoch Test 10, 299/1036\n","Epoch Test 10, 349/1036\n","Epoch Test 10, 399/1036\n","Epoch Test 10, 449/1036\n","Epoch Test 10, 499/1036\n","Epoch Test 10, 549/1036\n","Epoch Test 10, 599/1036\n","Epoch Test 10, 649/1036\n","Epoch Test 10, 699/1036\n","Epoch Test 10, 749/1036\n","Epoch Test 10, 799/1036\n","Epoch Test 10, 849/1036\n","Epoch Test 10, 899/1036\n","Epoch Test 10, 949/1036\n","Epoch Test 10, 999/1036\n","Epoch Test 10 cost time: 25.729s\n","准确率： 0.795\n","Epoch 11, 99/1036, loss:0.670046 \n","Epoch 11, 199/1036, loss:0.701928 \n","Epoch 11, 299/1036, loss:0.702169 \n","Epoch 11, 399/1036, loss:0.688700 \n","Epoch 11, 499/1036, loss:0.711063 \n","Epoch 11, 599/1036, loss:0.702277 \n","Epoch 11, 699/1036, loss:0.698368 \n","Epoch 11, 799/1036, loss:0.722712 \n","Epoch 11, 899/1036, loss:0.709306 \n","Epoch 11, 999/1036, loss:0.704625 \n","Epoch 11 cost time: 248.617s\n","Epoch Test 11, 49/1036\n","Epoch Test 11, 99/1036\n","Epoch Test 11, 149/1036\n","Epoch Test 11, 199/1036\n","Epoch Test 11, 249/1036\n","Epoch Test 11, 299/1036\n","Epoch Test 11, 349/1036\n","Epoch Test 11, 399/1036\n","Epoch Test 11, 449/1036\n","Epoch Test 11, 499/1036\n","Epoch Test 11, 549/1036\n","Epoch Test 11, 599/1036\n","Epoch Test 11, 649/1036\n","Epoch Test 11, 699/1036\n","Epoch Test 11, 749/1036\n","Epoch Test 11, 799/1036\n","Epoch Test 11, 849/1036\n","Epoch Test 11, 899/1036\n","Epoch Test 11, 949/1036\n","Epoch Test 11, 999/1036\n","Epoch Test 11 cost time: 25.613s\n","准确率： 0.794\n","Epoch 12, 99/1036, loss:0.699257 \n","Epoch 12, 199/1036, loss:0.693509 \n","Epoch 12, 299/1036, loss:0.707507 \n","Epoch 12, 399/1036, loss:0.669577 \n","Epoch 12, 499/1036, loss:0.720354 \n","Epoch 12, 599/1036, loss:0.697622 \n","Epoch 12, 699/1036, loss:0.690973 \n","Epoch 12, 799/1036, loss:0.716876 \n","Epoch 12, 899/1036, loss:0.708387 \n","Epoch 12, 999/1036, loss:0.713441 \n","Epoch 12 cost time: 248.550s\n","Epoch Test 12, 49/1036\n","Epoch Test 12, 99/1036\n","Epoch Test 12, 149/1036\n","Epoch Test 12, 199/1036\n","Epoch Test 12, 249/1036\n","Epoch Test 12, 299/1036\n","Epoch Test 12, 349/1036\n","Epoch Test 12, 399/1036\n","Epoch Test 12, 449/1036\n","Epoch Test 12, 499/1036\n","Epoch Test 12, 549/1036\n","Epoch Test 12, 599/1036\n","Epoch Test 12, 649/1036\n","Epoch Test 12, 699/1036\n","Epoch Test 12, 749/1036\n","Epoch Test 12, 799/1036\n","Epoch Test 12, 849/1036\n","Epoch Test 12, 899/1036\n","Epoch Test 12, 949/1036\n","Epoch Test 12, 999/1036\n","Epoch Test 12 cost time: 25.627s\n","准确率： 0.796\n","Epoch 13, 99/1036, loss:0.701962 \n","Epoch 13, 199/1036, loss:0.698851 \n","Epoch 13, 299/1036, loss:0.722346 \n","Epoch 13, 399/1036, loss:0.694172 \n","Epoch 13, 499/1036, loss:0.714094 \n","Epoch 13, 599/1036, loss:0.712238 \n","Epoch 13, 699/1036, loss:0.733714 \n","Epoch 13, 799/1036, loss:0.733621 \n","Epoch 13, 899/1036, loss:0.707795 \n","Epoch 13, 999/1036, loss:0.685210 \n","Epoch 13 cost time: 248.656s\n","Epoch Test 13, 49/1036\n","Epoch Test 13, 99/1036\n","Epoch Test 13, 149/1036\n","Epoch Test 13, 199/1036\n","Epoch Test 13, 249/1036\n","Epoch Test 13, 299/1036\n","Epoch Test 13, 349/1036\n","Epoch Test 13, 399/1036\n","Epoch Test 13, 449/1036\n","Epoch Test 13, 499/1036\n","Epoch Test 13, 549/1036\n","Epoch Test 13, 599/1036\n","Epoch Test 13, 649/1036\n","Epoch Test 13, 699/1036\n","Epoch Test 13, 749/1036\n","Epoch Test 13, 799/1036\n","Epoch Test 13, 849/1036\n","Epoch Test 13, 899/1036\n","Epoch Test 13, 949/1036\n","Epoch Test 13, 999/1036\n","Epoch Test 13 cost time: 25.626s\n","准确率： 0.796\n","Epoch 14, 99/1036, loss:0.701807 \n","Epoch 14, 199/1036, loss:0.693689 \n","Epoch 14, 299/1036, loss:0.690128 \n","Epoch 14, 399/1036, loss:0.691671 \n","Epoch 14, 499/1036, loss:0.714020 \n","Epoch 14, 599/1036, loss:0.708724 \n","Epoch 14, 699/1036, loss:0.702532 \n","Epoch 14, 799/1036, loss:0.730171 \n","Epoch 14, 899/1036, loss:0.684286 \n","Epoch 14, 999/1036, loss:0.710531 \n","Epoch 14 cost time: 248.547s\n","Epoch Test 14, 49/1036\n","Epoch Test 14, 99/1036\n","Epoch Test 14, 149/1036\n","Epoch Test 14, 199/1036\n","Epoch Test 14, 249/1036\n","Epoch Test 14, 299/1036\n","Epoch Test 14, 349/1036\n","Epoch Test 14, 399/1036\n","Epoch Test 14, 449/1036\n","Epoch Test 14, 499/1036\n","Epoch Test 14, 549/1036\n","Epoch Test 14, 599/1036\n","Epoch Test 14, 649/1036\n","Epoch Test 14, 699/1036\n","Epoch Test 14, 749/1036\n","Epoch Test 14, 799/1036\n","Epoch Test 14, 849/1036\n","Epoch Test 14, 899/1036\n","Epoch Test 14, 949/1036\n","Epoch Test 14, 999/1036\n","Epoch Test 14 cost time: 25.623s\n","准确率： 0.796\n","Epoch 15, 99/1036, loss:0.687668 \n","Epoch 15, 199/1036, loss:0.707690 \n","Epoch 15, 299/1036, loss:0.717036 \n","Epoch 15, 399/1036, loss:0.707410 \n","Epoch 15, 499/1036, loss:0.729281 \n","Epoch 15, 599/1036, loss:0.721511 \n","Epoch 15, 699/1036, loss:0.719385 \n","Epoch 15, 799/1036, loss:0.736451 \n","Epoch 15, 899/1036, loss:0.714819 \n","Epoch 15, 999/1036, loss:0.691653 \n","Epoch 15 cost time: 248.579s\n","Epoch Test 15, 49/1036\n","Epoch Test 15, 99/1036\n","Epoch Test 15, 149/1036\n","Epoch Test 15, 199/1036\n","Epoch Test 15, 249/1036\n","Epoch Test 15, 299/1036\n","Epoch Test 15, 349/1036\n","Epoch Test 15, 399/1036\n","Epoch Test 15, 449/1036\n","Epoch Test 15, 499/1036\n","Epoch Test 15, 549/1036\n","Epoch Test 15, 599/1036\n","Epoch Test 15, 649/1036\n","Epoch Test 15, 699/1036\n","Epoch Test 15, 749/1036\n","Epoch Test 15, 799/1036\n","Epoch Test 15, 849/1036\n","Epoch Test 15, 899/1036\n","Epoch Test 15, 949/1036\n","Epoch Test 15, 999/1036\n","Epoch Test 15 cost time: 25.644s\n","准确率： 0.797\n","Epoch 16, 99/1036, loss:0.717184 \n","Epoch 16, 199/1036, loss:0.705751 \n","Epoch 16, 299/1036, loss:0.723542 \n","Epoch 16, 399/1036, loss:0.719239 \n","Epoch 16, 499/1036, loss:0.720813 \n","Epoch 16, 599/1036, loss:0.717905 \n","Epoch 16, 699/1036, loss:0.702056 \n","Epoch 16, 799/1036, loss:0.702192 \n","Epoch 16, 899/1036, loss:0.700088 \n","Epoch 16, 999/1036, loss:0.711300 \n","Epoch 16 cost time: 248.624s\n","Epoch Test 16, 49/1036\n","Epoch Test 16, 99/1036\n","Epoch Test 16, 149/1036\n","Epoch Test 16, 199/1036\n","Epoch Test 16, 249/1036\n","Epoch Test 16, 299/1036\n","Epoch Test 16, 349/1036\n","Epoch Test 16, 399/1036\n","Epoch Test 16, 449/1036\n","Epoch Test 16, 499/1036\n","Epoch Test 16, 549/1036\n","Epoch Test 16, 599/1036\n","Epoch Test 16, 649/1036\n","Epoch Test 16, 699/1036\n","Epoch Test 16, 749/1036\n","Epoch Test 16, 799/1036\n","Epoch Test 16, 849/1036\n","Epoch Test 16, 899/1036\n","Epoch Test 16, 949/1036\n","Epoch Test 16, 999/1036\n","Epoch Test 16 cost time: 25.641s\n","准确率： 0.797\n","Epoch 17, 99/1036, loss:0.693617 \n","Epoch 17, 199/1036, loss:0.685707 \n","Epoch 17, 299/1036, loss:0.708995 \n","Epoch 17, 399/1036, loss:0.730484 \n","Epoch 17, 499/1036, loss:0.722955 \n","Epoch 17, 599/1036, loss:0.713664 \n","Epoch 17, 699/1036, loss:0.720127 \n","Epoch 17, 799/1036, loss:0.729342 \n","Epoch 17, 899/1036, loss:0.705477 \n","Epoch 17, 999/1036, loss:0.696038 \n","Epoch 17 cost time: 248.600s\n","Epoch Test 17, 49/1036\n","Epoch Test 17, 99/1036\n","Epoch Test 17, 149/1036\n","Epoch Test 17, 199/1036\n","Epoch Test 17, 249/1036\n","Epoch Test 17, 299/1036\n","Epoch Test 17, 349/1036\n","Epoch Test 17, 399/1036\n","Epoch Test 17, 449/1036\n","Epoch Test 17, 499/1036\n","Epoch Test 17, 549/1036\n","Epoch Test 17, 599/1036\n","Epoch Test 17, 649/1036\n","Epoch Test 17, 699/1036\n","Epoch Test 17, 749/1036\n","Epoch Test 17, 799/1036\n","Epoch Test 17, 849/1036\n","Epoch Test 17, 899/1036\n","Epoch Test 17, 949/1036\n","Epoch Test 17, 999/1036\n","Epoch Test 17 cost time: 25.645s\n","准确率： 0.797\n","Epoch 18, 99/1036, loss:0.745757 \n","Epoch 18, 199/1036, loss:0.711034 \n","Epoch 18, 299/1036, loss:0.721979 \n","Epoch 18, 399/1036, loss:0.688923 \n","Epoch 18, 499/1036, loss:0.691471 \n","Epoch 18, 599/1036, loss:0.708674 \n","Epoch 18, 699/1036, loss:0.713573 \n","Epoch 18, 799/1036, loss:0.714774 \n","Epoch 18, 899/1036, loss:0.726102 \n","Epoch 18, 999/1036, loss:0.713076 \n","Epoch 18 cost time: 248.745s\n","Epoch Test 18, 49/1036\n","Epoch Test 18, 99/1036\n","Epoch Test 18, 149/1036\n","Epoch Test 18, 199/1036\n","Epoch Test 18, 249/1036\n","Epoch Test 18, 299/1036\n","Epoch Test 18, 349/1036\n","Epoch Test 18, 399/1036\n","Epoch Test 18, 449/1036\n","Epoch Test 18, 499/1036\n","Epoch Test 18, 549/1036\n","Epoch Test 18, 599/1036\n","Epoch Test 18, 649/1036\n","Epoch Test 18, 699/1036\n","Epoch Test 18, 749/1036\n","Epoch Test 18, 799/1036\n","Epoch Test 18, 849/1036\n","Epoch Test 18, 899/1036\n","Epoch Test 18, 949/1036\n","Epoch Test 18, 999/1036\n","Epoch Test 18 cost time: 25.641s\n","准确率： 0.798\n","Epoch 19, 99/1036, loss:0.700642 \n","Epoch 19, 199/1036, loss:0.696137 \n","Epoch 19, 299/1036, loss:0.722075 \n","Epoch 19, 399/1036, loss:0.693826 \n","Epoch 19, 499/1036, loss:0.711944 \n","Epoch 19, 599/1036, loss:0.692273 \n","Epoch 19, 699/1036, loss:0.726844 \n","Epoch 19, 799/1036, loss:0.703956 \n","Epoch 19, 899/1036, loss:0.706475 \n","Epoch 19, 999/1036, loss:0.689489 \n","Epoch 19 cost time: 248.741s\n","Epoch Test 19, 49/1036\n","Epoch Test 19, 99/1036\n","Epoch Test 19, 149/1036\n","Epoch Test 19, 199/1036\n","Epoch Test 19, 249/1036\n","Epoch Test 19, 299/1036\n","Epoch Test 19, 349/1036\n","Epoch Test 19, 399/1036\n","Epoch Test 19, 449/1036\n","Epoch Test 19, 499/1036\n","Epoch Test 19, 549/1036\n","Epoch Test 19, 599/1036\n","Epoch Test 19, 649/1036\n","Epoch Test 19, 699/1036\n","Epoch Test 19, 749/1036\n","Epoch Test 19, 799/1036\n","Epoch Test 19, 849/1036\n","Epoch Test 19, 899/1036\n","Epoch Test 19, 949/1036\n","Epoch Test 19, 999/1036\n","Epoch Test 19 cost time: 25.642s\n","准确率： 0.796\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gzvump0AVdJY","colab_type":"code","colab":{}},"source":["\n","def eval(model, modelSavePath, isLoad = True):\n","    if isLoad: model.load_state_dict(torch.load(modelSavePath))\n","    testModel(0, model, testLoader)\n","\n","eval(model, 'EmotionAnalyzeModelData_ClassicalHAN_OB_plus.model', isLoad = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"wKXjE4UBTodM","colab_type":"code","colab":{}},"source":["lossFunc =torch.nn.CrossEntropyLoss()\n","input = torch.randn(3, 5, requires_grad=True)\n","target = torch.empty(3, dtype=torch.long).random_(5)\n","_, predicted = torch.max(input.data, 1)\n","output = lossFunc(input, target)\n","print('input',input, '\\n target',target, '\\n output', output)\n","output = lossFunc(input, predicted)\n","print('predicted',predicted, '\\n target',target, '\\n output', output)\n","\n","print(predicted.data.eq(target).cpu().sum())\n","print(target.data.eq(predicted).cpu().sum())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Z1zQWh6DTodQ","colab_type":"code","colab":{}},"source":["# 何凯明初始化\n","\n","w = torch.Tensor(3, 5, 2)\n","print(w)\n","print(nn.init.kaiming_uniform(w))\n","print(w)\n","w = torch.Tensor(3, 5, 2)\n","print(w)\n","print(torch.nn.init.kaiming_normal(w))\n","print(w)"],"execution_count":0,"outputs":[]}]}